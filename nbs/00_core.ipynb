{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|default_exp core"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "from fastcore.imports import *\n",
    "from fastcore.foundation import *\n",
    "from fastcore.utils import *\n",
    "from fastcore.dispatch import *\n",
    "import inspect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "from nbdev.showdoc import *\n",
    "from fastcore.test import *\n",
    "from fastcore.nb_imports import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Core\n",
    "\n",
    "> Definition of `Transform` and `Pipeline`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The classes here provide functionality for creating a composition of *partially reversible functions*. By \"partially reversible\" we mean that a transform can be `decode`d, creating a form suitable for display. This is not necessarily identical to the original form (e.g. a transform that changes a byte tensor to a float tensor does not recreate a byte tensor when decoded, since that may lose precision, and a float tensor can be displayed already).\n",
    "\n",
    "Classes are also provided and for composing transforms, and mapping them over collections. `Pipeline` is a transform which composes several `Transform`, knowing how to decode them or show an encoded item."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transform -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "_tfm_methods = 'encodes','decodes','setups'\n",
    "\n",
    "def _is_tfm_method(n, f): return n in _tfm_methods and callable(f)\n",
    "\n",
    "class _TfmDict(dict):\n",
    "    def __setitem__(self, k, v):\n",
    "        # regular items are added to dict\n",
    "        if not _is_tfm_method(k, v): return super().__setitem__(k,v)\n",
    "        # special items if not present, are initialized TypeDispatch obj\n",
    "        if k not in self: super().__setitem__(k,TypeDispatch())\n",
    "        # and added to the type dispatch obj\n",
    "        self[k].add(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "class _TfmMeta(type):\n",
    "    def __new__(cls, name, bases, dict):\n",
    "        res = super().__new__(cls, name, bases, dict)\n",
    "        for nm in _tfm_methods:\n",
    "            base_td = [getattr(b,nm,None) for b in bases]\n",
    "            if nm in res.__dict__: getattr(res,nm).bases = base_td\n",
    "            else: setattr(res, nm, TypeDispatch(bases=base_td))\n",
    "        # _TfmMeta.__call__ shadows the signature of inheriting classes, set it back\n",
    "        res.__signature__ = inspect.signature(res.__init__)\n",
    "        return res\n",
    "\n",
    "    def __call__(cls, *args, **kwargs):\n",
    "        f = first(args)\n",
    "        n = getattr(f, '__name__', None)\n",
    "        if _is_tfm_method(n, f):\n",
    "            getattr(cls,n).add(f)\n",
    "            return f\n",
    "        obj = super().__call__(*args, **kwargs)\n",
    "        # _TfmMeta.__new__ replaces cls.__signature__ which breaks the signature of a callable\n",
    "        # instances of cls, fix it\n",
    "        if hasattr(obj, '__call__'): obj.__signature__ = inspect.signature(obj.__call__)\n",
    "        return obj\n",
    "\n",
    "    @classmethod\n",
    "    def __prepare__(cls, name, bases): \n",
    "        # by default type.prepare returns a regular dictionary {}\n",
    "        return _TfmDict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "def _get_name(o):\n",
    "    if hasattr(o,'__qualname__'): return o.__qualname__\n",
    "    if hasattr(o,'__name__'): return o.__name__\n",
    "    return o.__class__.__name__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "def _is_tuple(o): return isinstance(o, tuple) and not hasattr(o, '_fields')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "class Transform(metaclass=_TfmMeta):\n",
    "    \"Delegates (`__call__`,`decode`,`setup`) to (<code>encodes</code>,<code>decodes</code>,<code>setups</code>) if `split_idx` matches\"\n",
    "    split_idx,init_enc,order,train_setup = None,None,0,None\n",
    "    def __init__(self, enc=None, dec=None, split_idx=None, order=None):\n",
    "        self.split_idx = ifnone(split_idx, self.split_idx)\n",
    "        if order is not None: self.order=order\n",
    "        self.init_enc = enc or dec\n",
    "        if not self.init_enc: return\n",
    "\n",
    "        self.encodes,self.decodes,self.setups = TypeDispatch(),TypeDispatch(),TypeDispatch()\n",
    "        if enc:\n",
    "            self.encodes.add(enc)\n",
    "            self.order = getattr(enc,'order',self.order)\n",
    "            if len(type_hints(enc)) > 0: self.input_types = union2tuple(first(type_hints(enc).values()))\n",
    "            self._name = _get_name(enc)\n",
    "        if dec: self.decodes.add(dec)\n",
    "\n",
    "    @property\n",
    "    def name(self): return getattr(self, '_name', _get_name(self))\n",
    "    def __call__(self, x, **kwargs): \n",
    "        return self._call('encodes', x, **kwargs)\n",
    "    def decode  (self, x, **kwargs): return self._call('decodes', x, **kwargs)\n",
    "    def __repr__(self): return f'{self.name}:\\nencodes: {self.encodes}decodes: {self.decodes}'\n",
    "\n",
    "    def setup(self, items=None, train_setup=False):\n",
    "        train_setup = train_setup if self.train_setup is None else self.train_setup\n",
    "        return self.setups(getattr(items, 'train', items) if train_setup else items)\n",
    "\n",
    "    def _call(self, fn, x, split_idx=None, **kwargs):\n",
    "        if split_idx!=self.split_idx and self.split_idx is not None: return x\n",
    "        return self._do_call(getattr(self, fn), x, **kwargs)\n",
    "\n",
    "    def _do_call(self, f, x, **kwargs):\n",
    "        if not _is_tuple(x):\n",
    "            if f is None: return x\n",
    "            ret = f.returns(x) if hasattr(f,'returns') else None\n",
    "            return retain_type(f(x, **kwargs), x, ret)\n",
    "        res = tuple(self._do_call(f, x_, **kwargs) for x_ in x)\n",
    "        return retain_type(res, x)\n",
    "\n",
    "add_docs(Transform, decode=\"Delegate to <code>decodes</code> to undo transform\", setup=\"Delegate to <code>setups</code> to set up transform\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/AnswerDotAI/fasttransform/blob/main/fasttransform/core.py#L74){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### Transform\n",
       "\n",
       ">      Transform (enc=None, dec=None, split_idx=None, order=None)\n",
       "\n",
       "*Delegates (`__call__`,`decode`,`setup`) to (<code>encodes</code>,<code>decodes</code>,<code>setups</code>) if `split_idx` matches*"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/AnswerDotAI/fasttransform/blob/main/fasttransform/core.py#L74){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### Transform\n",
       "\n",
       ">      Transform (enc=None, dec=None, split_idx=None, order=None)\n",
       "\n",
       "*Delegates (`__call__`,`decode`,`setup`) to (<code>encodes</code>,<code>decodes</code>,<code>setups</code>) if `split_idx` matches*"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(Transform)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A `Transform` is the main building block of the fastai data pipelines. In the most general terms a transform can be any function you want to apply to your data, however the `Transform` class provides several mechanisms that make the process of building them easy and flexible."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The main `Transform` features:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Type dispatch** - Type annotations are used to determine if a transform should be applied to the given argument. It also gives an option to provide several implementations and it choses the one to run based on the type. This is useful for example when running both independent and dependent variables through the pipeline where some transforms only make sense for one and not the other. Another usecase is designing a transform that handles different data formats. Note that if a transform takes multiple arguments only the type of the first one is used for dispatch. \n",
    "- **Handling of tuples** - When a tuple (or a subclass of tuple) of data is passed to a transform it will get applied to each element separately. You can opt out of this behavior by passing a list or an `L`, as only tuples gets this specific behavior. An alternative is to use `ItemTransform` defined below, which will always take the input as a whole.\n",
    "- **Reversability** - A transform can be made reversible by implementing the <code>decodes</code> method. This is mainly used to turn something like a category which is encoded as a number back into a label understandable by humans for showing purposes. Like the regular call method, the `decode` method that is used to decode will be applied over each element of a tuple separately.\n",
    "- **Type propagation** - Whenever possible a transform tries to return data of the same type it received. Mainly used to maintain semantics of things like `ArrayImage` which is a thin wrapper of pytorch's `Tensor`. You can opt out of this behavior by adding `->None` return type annotation.\n",
    "- **Preprocessing** - The `setup` method can be used to perform any one-time calculations to be later used by the transform, for example generating a vocabulary to encode categorical data.\n",
    "- **Filtering based on the dataset type** - By setting the `split_idx` flag you can make the transform be used only in a specific `DataSource` subset like in training, but not validation.\n",
    "- **Ordering** - You can set the `order` attribute which the `Pipeline` uses when it needs to merge two lists of transforms.\n",
    "- **Appending new behavior with decorators** - You can easily extend an existing `Transform` by creating <code>encodes</code> or <code>decodes</code> methods for new data types. You can put those new methods outside the original transform definition and decorate them with the class you wish them patched into. This can be used by the fastai library users to add their own behavior, or multiple modules contributing to the same transform."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## New definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from plum import Function\n",
    "\n",
    "_tfm_methods = 'encodes','decodes','setups'\n",
    "\n",
    "class Transform:\n",
    "    @staticmethod\n",
    "    def _default(self, x, *args, **kwargs): return x\n",
    "    \n",
    "    def __new__(cls, *args, **kwargs):\n",
    "        # No args - regular instantiation\n",
    "        if not args: return super().__new__(cls)\n",
    "        \n",
    "        func = args[0]\n",
    "        \n",
    "        # Not callable - regular instantiation\n",
    "        if not callable(func): return super().__new__(cls)\n",
    "            \n",
    "        # Decorator mode for encodes/decodes/setups\n",
    "        if func.__name__ in _tfm_methods:\n",
    "            if not hasattr(cls, func.__name__):\n",
    "                setattr(cls, func.__name__, Function(func).dispatch(func))\n",
    "            else:\n",
    "                existing = getattr(cls, func.__name__)\n",
    "                if not isinstance(existing, Function):\n",
    "                    # If attribute exists but isn't a Function yet, create one\n",
    "                    new_func = Function(existing).dispatch(existing)\n",
    "                    new_func.dispatch(func)\n",
    "                    setattr(cls, func.__name__, new_func)\n",
    "                else:\n",
    "                    existing.dispatch(func)\n",
    "            return func\n",
    "\n",
    "        # Direct function mode\n",
    "        inst = super().__new__(cls)\n",
    "        def encodes(self, *args, **kwargs): return func(*args, **kwargs)\n",
    "        def decodes(self, *args, **kwargs): return args[0] # Identity function\n",
    "        inst.encodes = Function(encodes).dispatch(encodes)\n",
    "        inst.decodes = Function(decodes).dispatch(decodes)\n",
    "        return inst\n",
    "                \n",
    "    def __init__(self, *args, **kwargs):\n",
    "        if not args or not callable(args[0]):\n",
    "            self.encodes = getattr(self.__class__, 'encodes', Function(self._default).dispatch(self._default))\n",
    "            self.decodes = getattr(self.__class__, 'decodes', Function(self._default).dispatch(self._default))\n",
    "        \n",
    "    def __call__(self, *args, **kwargs):\n",
    "        return self.encodes(self, *args, **kwargs)\n",
    "    \n",
    "    def decode(self, *args, **kwargs):\n",
    "        return self.decodes(self, *args, **kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining a `Transform`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are a few ways to create a transform with different ratios of simplicity to flexibility.\n",
    "- **Extending the `Transform` class** - Use inheritence to implement the methods you want.\n",
    "- **Passing methods to the constructor** - Instantiate the `Transform` class and pass your functions as `enc` and `dec` arguments.\n",
    "- **@Transform decorator** - Turn any function into a `Transform` by just adding a decorator - very straightforward if all you need is a single <code>encodes</code> implementation.\n",
    "- **Passing a function to fastai APIs** - Same as above, but when passing a function to other transform aware classes like `Pipeline` or `TfmdDS` you don't even need a decorator. Your function will get converted to a `Transform` automatically."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A simple way to create a `Transform` is to pass a function to the constructor.  In the below example, we pass an anonymous function that does integer division by 2:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = Transform(lambda o:o//2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you call this transform, it will apply the transformation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_eq_type(f(2), 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another way to define a Transform is to extend the `Transform` class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class A(Transform): pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, to enable your transform to do something, you have to define an <code>encodes</code> method.  Note that we can use the class name as a decorator to add this method to the original class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "@A\n",
    "def encodes(self, x): return x+1\n",
    "\n",
    "f1 = A()\n",
    "test_eq(f1(1), 2) # f1(1) is the same as f1.encode(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In addition to adding an <code>encodes</code> method, we can also add a <code>decodes</code> method.  This enables you to call the `decode` method (without an s).  For more information about the purpose of <code>decodes</code>, see the discussion about Reversibility in [the above section](#The-main-Transform-features)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just like with encodes, you can add a <code>decodes</code> method to the original class by using the class name as a decorator:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class B(A): pass\n",
    "\n",
    "@B\n",
    "def decodes(self, x): return x-1\n",
    "\n",
    "f2 = B()\n",
    "test_eq(f2.decode(2), 1)\n",
    "\n",
    "test_eq(f2(1), 2) # uses A's encode method from the parent class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you do not define an <code>encodes</code> or <code>decodes</code> method the original value will be returned:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class _Tst(Transform): pass \n",
    "\n",
    "f3 = _Tst() # no encodes or decodes method have been defined\n",
    "test_eq_type(f3.decode(2.0), 2.0)\n",
    "test_eq_type(f3(2), 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transforms can be created from class methods too:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class A:\n",
    "    @classmethod\n",
    "    def create(cls, x:int): return x+1\n",
    "test_eq(Transform(A.create)(1), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|hide\n",
    "# Test extension of a tfm method defined in the class\n",
    "class A(Transform):\n",
    "    def encodes(self, x:float): return 'obj'\n",
    "\n",
    "@A\n",
    "def encodes(self, x:int): return 'int'\n",
    "\n",
    "a = A()\n",
    "test_eq(a.encodes(0), 'int')\n",
    "test_eq(a.encodes(0.0), 'obj')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "error on run (printed because printing style is breaking aimagic):\n",
    "\n",
    "```python\n",
    "---------------------------------------------------------------------------\n",
    "NotFoundLookupError                       Traceback (most recent call last)\n",
    "Cell In[22], line 10\n",
    "      7 def encodes(self, x:int): return 'int'\n",
    "      9 a = A()\n",
    "---> 10 test_eq(a.encodes(0), 'int')\n",
    "     11 test_eq(a.encodes(0.0), 'obj')\n",
    "\n",
    "    [... skipping hidden 3 frame]\n",
    "\n",
    "File ~/.venv/lib/python3.12/site-packages/plum/function.py:342, in Function._handle_not_found_lookup_error(self, ex)\n",
    "    337 def _handle_not_found_lookup_error(\n",
    "    338     self, ex: NotFoundLookupError\n",
    "    339 ) -> Tuple[Callable, TypeHint]:\n",
    "    340     if not self.owner:\n",
    "    341         # Not in a class. Nothing we can do.\n",
    "--> 342         raise ex from None\n",
    "    344     # In a class. Walk through the classes in the class's MRO, except for this\n",
    "    345     # class, and try to get the method.\n",
    "    346     method = None\n",
    "\n",
    "    [... skipping hidden 1 frame]\n",
    "\n",
    "File ~/.venv/lib/python3.12/site-packages/plum/resolver.py:377, in Resolver.resolve(self, target)\n",
    "    373         candidates = new_candidates\n",
    "    375 if len(candidates) == 0:\n",
    "    376     # There is no matching signature.\n",
    "--> 377     raise NotFoundLookupError(self.function_name, target, self.methods)\n",
    "    379 elif len(candidates) == 1:\n",
    "    380     # There is exactly one matching signature. Success!\n",
    "    381     return candidates[0]\n",
    "\n",
    "NotFoundLookupError: `encodes(0)` could not be resolved.\n",
    "\n",
    "Closest candidates are the following:\n",
    "    encodes(self: Any, x: float)                                                                                   \n",
    "        <function A.encodes at 0x14cdbfb00> @                                                                      \n",
    "    \u001b]8;id=927983;file:///var/folders/0h/5ktbjhg17ns6j8zgdsgvzvy80000gn/T/ipykernel_89165/2308107119.py#4\u001b\\/var/folders/0h/5ktbjhg17ns6j8zgdsgvzvy80000gn/T/ipykernel_89165/\u001b]8;;\u001b\\\u001b]8;id=233346;file:///var/folders/0h/5ktbjhg17ns6j8zgdsgvzvy80000gn/T/ipykernel_89165/2308107119.py#4\u001b\\2308107119.py\u001b]8;;\u001b\\\u001b]8;id=927983;file:///var/folders/0h/5ktbjhg17ns6j8zgdsgvzvy80000gn/T/ipykernel_89165/2308107119.py#4\u001b\\:4\u001b]8;;\u001b\\                               \n",
    "    encodes(self: Any, x: int)                                                                                     \n",
    "        <function encodes at 0x14cdbe020> @                                                                        \n",
    "    \u001b]8;id=76461;file:///var/folders/0h/5ktbjhg17ns6j8zgdsgvzvy80000gn/T/ipykernel_89165/2308107119.py#6\u001b\\/var/folders/0h/5ktbjhg17ns6j8zgdsgvzvy80000gn/T/ipykernel_89165/\u001b]8;;\u001b\\\u001b]8;id=801271;file:///var/folders/0h/5ktbjhg17ns6j8zgdsgvzvy80000gn/T/ipykernel_89165/2308107119.py#6\u001b\\2308107119.py\u001b]8;;\u001b\\\u001b]8;id=76461;file:///var/folders/0h/5ktbjhg17ns6j8zgdsgvzvy80000gn/T/ipykernel_89165/2308107119.py#6\u001b\\:6\u001b]8;;\u001b\\       \n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%ai\n",
    "\n",
    "why does my implementation not work?\n",
    "explain with snippets dont improve all code at once"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The main issue appears to be with how method dispatch is working in the implementation. Let's break down the key problems:\n",
    "\n",
    "1. First issue is in how we're handling the instance methods. When we create the Function objects, we're including `self` in the type hints:\n",
    "\n",
    "```python\n",
    "def encodes(self, x:float): return 'obj'  # in class\n",
    "def encodes(self, x:int): return 'int'    # decorator version\n",
    "```\n",
    "\n",
    "The plum Function is seeing these as methods requiring different types for `self`, when we want to ignore `self` in the dispatch. We can fix this part by modifying how we create the Function:\n",
    "\n",
    "```python\n",
    "class Transform:\n",
    "    def __new__(cls, *args, **kwargs):\n",
    "        # ... other code ...\n",
    "        \n",
    "        # For decorator mode, we should wrap the function to ignore self in dispatch\n",
    "        if func.__name__ in _tfm_methods:\n",
    "            def wrapped(*args, **kwargs):\n",
    "                # Skip self in dispatch\n",
    "                return func(*args, **kwargs)\n",
    "            \n",
    "            if not hasattr(cls, func.__name__):\n",
    "                setattr(cls, func.__name__, Function(wrapped))\n",
    "            else:\n",
    "                existing = getattr(cls, func.__name__)\n",
    "                if not isinstance(existing, Function):\n",
    "                    new_func = Function(existing)\n",
    "                    new_func.dispatch(wrapped)\n",
    "                    setattr(cls, func.__name__, new_func)\n",
    "                else:\n",
    "                    existing.dispatch(wrapped)\n",
    "            return func\n",
    "```\n",
    "\n",
    "2. The second issue is that we're not properly handling instance vs class methods. When we create an instance, we need to bind the Function to it:\n",
    "\n",
    "```python\n",
    "def __init__(self, *args, **kwargs):\n",
    "    if not args or not callable(args[0]):\n",
    "        # Create bound methods for this instance\n",
    "        def bind(f):\n",
    "            return lambda *a, **k: f(self, *a, **k)\n",
    "        \n",
    "        self.encodes = bind(getattr(self.__class__, 'encodes', \n",
    "                           Function(self._default)))\n",
    "        self.decodes = bind(getattr(self.__class__, 'decodes',\n",
    "                           Function(self._default)))\n",
    "```\n",
    "\n",
    "Would you like me to continue with other issues, or would you like to try implementing these changes first to see how they affect the behavior?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‼️ **END OF DAY**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Defining Transforms With A Decorator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Transform` can be used as a decorator to turn a function into a `Transform`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@Transform\n",
    "def f(x): return x//2\n",
    "test_eq_type(f(2), 1)\n",
    "test_eq_type(f.decode(2.0), 2.0)\n",
    "\n",
    "@Transform\n",
    "def f(x): return x*2\n",
    "test_eq_type(f(2), 4)\n",
    "test_eq_type(f.decode(2.0), 2.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Typed Dispatch and Transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also apply different transformations depending on the type of the input passed by using `TypedDispatch`.  `TypedDispatch` automatically works with `Transform` when using type hints:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class A(Transform): pass\n",
    "\n",
    "@A\n",
    "def encodes(self, x:int): return x//2\n",
    "\n",
    "@A\n",
    "def encodes(self, x:float): return x+1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we pass in an `int`, this calls the first encodes method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = A()\n",
    "test_eq_type(f(3), 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we pass in a `float`, this calls the second encodes method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_eq_type(f(2.), 3.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we pass in a type that is not specified in <code>encodes</code>, the original value is returned:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_eq(f('a'), 'a')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the type annotation is a tuple, then any type in the tuple will match:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyClass(int): pass\n",
    "\n",
    "class A(Transform):\n",
    "    def encodes(self, x:MyClass|float): return x/2\n",
    "    def encodes(self, x:str|list): return str(x)+'_1'\n",
    "\n",
    "f = A()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The below two examples match the first encodes, with a type of `MyClass` and `float`, respectively:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_eq(f(MyClass(2)), 1.) # input is of type MyClass \n",
    "test_eq(f(6.0), 3.0) # input is of type float"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next two examples match the second `encodes` method, with a type of `str` and `list`, respectively:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_eq(f('a'), 'a_1') # input is of type str\n",
    "test_eq(f(['a','b','c']), \"['a', 'b', 'c']_1\") # input is of type list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Casting Types With Transform"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Without any intervention it is easy for operations to change types in Python. For example, `FloatSubclass` (defined below) becomes a `float` after performing multiplication:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FloatSubclass(float): pass\n",
    "test_eq_type(FloatSubclass(3.0) * 2, 6.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This behavior is often not desirable when performing transformations on data.  Therefore, `Transform` will attempt to cast the output to be of the same type as the input by default.  In the below example, the output will be cast to a `FloatSubclass` type to match the type of the input:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@Transform\n",
    "def f(x): return x*2\n",
    "\n",
    "test_eq_type(f(FloatSubclass(3.0)), FloatSubclass(6.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can optionally turn off casting by annotating the transform function with a return type of `None`:  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@Transform\n",
    "def f(x)-> None: return x*2 # Same transform as above, but with a -> None annotation\n",
    "\n",
    "test_eq_type(f(FloatSubclass(3.0)), 6.0)  # Casting is turned off because of -> None annotation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, `Transform` will only cast output back to the input type when the input is a subclass of the output.  In the below example, the input is of type `FloatSubclass` which is not a subclass of the output which is of type `str`.  Therefore, the output doesn't get cast back to `FloatSubclass` and stays as type `str`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@Transform\n",
    "def f(x): return str(x)\n",
    "    \n",
    "test_eq_type(f(Float(2.)), '2.0')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just like <code>encodes</code>, the <code>decodes</code> method will cast outputs to match the input type in the same way.  In the below example, the output of <code>decodes</code> remains of type `MySubclass`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MySubclass(int): pass\n",
    "\n",
    "def enc(x): return MySubclass(x+1)\n",
    "def dec(x): return x-1\n",
    "\n",
    "\n",
    "f = Transform(enc,dec)\n",
    "t = f(1) # t is of type MySubclass\n",
    "test_eq_type(f.decode(t), MySubclass(1)) # the output of decode is cast to MySubclass to match the input type."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Apply Transforms On Subsets With `split_idx`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can apply transformations to subsets of data by specifying a `split_idx` property. If a transform has a `split_idx` then it's only applied if the `split_idx` param matches.  In the below example, we set `split_idx` equal to `1`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def enc(x): return x+1\n",
    "def dec(x): return x-1\n",
    "f = Transform(enc,dec)\n",
    "f.split_idx = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The transformations are applied when a matching `split_idx` parameter is passed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_eq(f(1, split_idx=1),2)\n",
    "test_eq(f.decode(2, split_idx=1),1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On the other hand, transformations are ignored when the `split_idx` parameter does not match:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_eq(f(1, split_idx=0), 1)\n",
    "test_eq(f.decode(2, split_idx=0), 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Transforms on Lists"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transform operates on lists as a whole, **not element-wise**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class A(Transform):\n",
    "    def encodes(self, x): return dict(x)\n",
    "    def decodes(self, x): return list(x.items())\n",
    "    \n",
    "f = A()\n",
    "_inp = [(1,2), (3,4)]\n",
    "t = f(_inp)\n",
    "\n",
    "test_eq(t, dict(_inp))\n",
    "test_eq(f.decodes(t), _inp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|hide\n",
    "f.split_idx = 1\n",
    "test_eq(f(_inp, split_idx=1), dict(_inp))\n",
    "test_eq(f(_inp, split_idx=0), _inp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want a transform to operate on a list elementwise, you must implement this appropriately in the <code>encodes</code> and <code>decodes</code> methods:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AL(Transform): pass\n",
    "\n",
    "@AL\n",
    "def encodes(self, x): return [x_+1 for x_ in x]\n",
    "\n",
    "@AL\n",
    "def decodes(self, x): return [x_-1 for x_ in x]\n",
    "\n",
    "f = AL()\n",
    "t = f([1,2])\n",
    "\n",
    "test_eq(t, [2,3])\n",
    "test_eq(f.decode(t), [1,2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Transforms on Tuples\n",
    "\n",
    "Unlike lists, `Transform` operates on tuples element-wise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def neg_int(x): return -x\n",
    "f = Transform(neg_int)\n",
    "\n",
    "test_eq(f((1,2,3)), (-1,-2,-3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transforms will also apply `TypedDispatch` element-wise on tuples when an input type annotation is specified.  In the below example, the values `1.0` and `3.0` are ignored because they are of type `float`, not `int`: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def neg_int(x:int): return -x\n",
    "f = Transform(neg_int)\n",
    "\n",
    "test_eq(f((1.0, 2, 3.0)), (1.0, -2, 3.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|hide\n",
    "test_eq(f((1,)), (-1,))\n",
    "test_eq(f((1.,)), (1.,))\n",
    "test_eq(f.decode((1,2)), (1,2))\n",
    "test_eq(f.input_types, int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another example of how `Transform` can use `TypedDispatch` with tuples is shown below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class B(Transform): pass\n",
    "\n",
    "@B\n",
    "def encodes(self, x:int): return x+1\n",
    "\n",
    "@B\n",
    "def encodes(self, x:str): return x+'hello'\n",
    "\n",
    "@B\n",
    "def encodes(self, x): return str(x)+'!'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the input is not an `int` or `str`, the third `encodes` method will apply:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = B()\n",
    "test_eq(b([1]), '[1]!') \n",
    "test_eq(b([1.0]), '[1.0]!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, if the input is a tuple, then the appropriate method will apply according to the type of each element in the tuple:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_eq(b(('1',)), ('1hello',))\n",
    "test_eq(b((1,2)), (2,3))\n",
    "test_eq(b(('a',1.0)), ('ahello','1.0!'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|hide\n",
    "@B\n",
    "def decodes(self, x:int): return x-1\n",
    "\n",
    "test_eq(b.decode((2,)), (1,))\n",
    "test_eq(b.decode(('2',)), ('2',))\n",
    "assert pickle.loads(pickle.dumps(b))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dispatching over tuples works recursively, by the way:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class B(Transform):\n",
    "    def encodes(self, x:int): return x+1\n",
    "    def encodes(self, x:str): return x+'_hello'\n",
    "    def decodes(self, x:int): return x-1\n",
    "    def decodes(self, x:str): return x.replace('_hello', '')\n",
    "\n",
    "f = B()\n",
    "start = (1.,(2,'3'))\n",
    "t = f(start)\n",
    "test_eq_type(t, (1.,(3,'3_hello')))\n",
    "test_eq(f.decode(t), start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dispatching also works with `typing` module type classes, like `numbers.integral`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@Transform\n",
    "def f(x:numbers.Integral): return x+1\n",
    "\n",
    "t = f((1,'1',1))\n",
    "test_eq(t, (2, '1', 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "class InplaceTransform(Transform):\n",
    "    \"A `Transform` that modifies in-place and just returns whatever it's passed\"\n",
    "    def _call(self, fn, x, split_idx=None, **kwargs):\n",
    "        super()._call(fn,x,split_idx,**kwargs)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|hide\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class A(InplaceTransform): pass\n",
    "\n",
    "@A\n",
    "def encodes(self, x:pd.Series): x.fillna(10, inplace=True)\n",
    "    \n",
    "f = A()\n",
    "\n",
    "test_eq_type(f(pd.Series([1,2,None])),pd.Series([1,2,10],dtype=np.float64)) #fillna fills with floats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "class DisplayedTransform(Transform):\n",
    "    \"A transform with a `__repr__` that shows its attrs\"\n",
    "\n",
    "    @property\n",
    "    def name(self): return f\"{super().name} -- {getattr(self,'__stored_args__',{})}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transforms normally are represented by just their class name and a list of encodes and decodes implementations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class A(Transform): encodes,decodes = noop,noop\n",
    "f = A()\n",
    "f"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A `DisplayedTransform` will in addition show the contents of all attributes listed in the comma-delimited string `self.store_attrs`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class A(DisplayedTransform):\n",
    "    encodes = noop\n",
    "    def __init__(self, a, b=2):\n",
    "        super().__init__()\n",
    "        store_attr()\n",
    "    \n",
    "A(a=1,b=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ItemTransform -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "class ItemTransform(Transform):\n",
    "    \"A transform that always take tuples as items\"\n",
    "    _retain = True\n",
    "    def __call__(self, x, **kwargs): return self._call1(x, '__call__', **kwargs)\n",
    "    def decode(self, x, **kwargs):   return self._call1(x, 'decode', **kwargs)\n",
    "    def _call1(self, x, name, **kwargs):\n",
    "        if not _is_tuple(x): return getattr(super(), name)(x, **kwargs)\n",
    "        y = getattr(super(), name)(list(x), **kwargs)\n",
    "        if not self._retain: return y\n",
    "        if is_listy(y) and not isinstance(y, tuple): y = tuple(y)\n",
    "        return retain_type(y, x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`ItemTransform` is the class to use to opt out of the default behavior of `Transform`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AIT(ItemTransform): \n",
    "    def encodes(self, xy): x,y=xy; return (x+y,y)\n",
    "    def decodes(self, xy): x,y=xy; return (x-y,y)\n",
    "    \n",
    "f = AIT()\n",
    "test_eq(f((1,2)), (3,2))\n",
    "test_eq(f.decode((3,2)), (1,2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you pass a special tuple subclass, the usual retain type behavior of `Transform` will keep it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class _T(tuple): pass\n",
    "x = _T((1,2))\n",
    "test_eq_type(f(x), _T((3,2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|hide\n",
    "f.split_idx = 0\n",
    "test_eq_type(f((1,2)), (1,2))\n",
    "test_eq_type(f((1,2), split_idx=0), (3,2))\n",
    "test_eq_type(f.decode((1,2)), (1,2))\n",
    "test_eq_type(f.decode((3,2), split_idx=0), (1,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|hide\n",
    "class Get(ItemTransform):\n",
    "    _retain = False\n",
    "    def encodes(self, x): return x[0]\n",
    "    \n",
    "g = Get()\n",
    "test_eq(g([1,2,3]), 1)\n",
    "test_eq(g(L(1,2,3)), 1)\n",
    "test_eq(g(np.array([1,2,3])), 1)\n",
    "test_eq_type(g((['a'], ['b', 'c'])), ['a'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|hide\n",
    "class A(ItemTransform): \n",
    "    def encodes(self, x): return _T((x,x))\n",
    "    def decodes(self, x): return _T(x)\n",
    "    \n",
    "f = A()\n",
    "test_eq(type(f.decode((1,1))), _T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Func -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "def get_func(t, name, *args, **kwargs):\n",
    "    \"Get the `t.name` (potentially partial-ized with `args` and `kwargs`) or `noop` if not defined\"\n",
    "    f = nested_callable(t, name)\n",
    "    return f if not (args or kwargs) else partial(f, *args, **kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This works for any kind of `t` supporting `getattr`, so a class or a module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_eq(get_func(operator, 'neg', 2)(), -2)\n",
    "test_eq(get_func(operator.neg, '__call__')(2), -2)\n",
    "test_eq(get_func(list, 'foobar')([2]), [2])\n",
    "a = [2,1]\n",
    "get_func(list, 'sort')(a)\n",
    "test_eq(a, [1,2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transforms are built with multiple-dispatch: a given function can have several methods depending on the type of the object received. This is done directly with the `TypeDispatch` module and type-annotation in `Transform`, but you can also use the following class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "class Func():\n",
    "    \"Basic wrapper around a `name` with `args` and `kwargs` to call on a given type\"\n",
    "    def __init__(self, name, *args, **kwargs): self.name,self.args,self.kwargs = name,args,kwargs\n",
    "    def __repr__(self): return f'sig: {self.name}({self.args}, {self.kwargs})'\n",
    "    def _get(self, t): return get_func(t, self.name, *self.args, **self.kwargs)\n",
    "    def __call__(self,t): return mapped(self._get, t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can call the `Func` object on any module name or type, even a list of types. It will return the corresponding function (with a default to `noop` if nothing is found) or list of functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_eq(Func('sqrt')(math), math.sqrt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "class _Sig():\n",
    "    def __getattr__(self,k):\n",
    "        def _inner(*args, **kwargs): return Func(k, *args, **kwargs)\n",
    "        return _inner\n",
    "\n",
    "Sig = _Sig()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(Sig, name=\"Sig\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Sig` is just sugar-syntax to create a `Func` object more easily with the syntax `Sig.name(*args, **kwargs)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = Sig.sqrt()\n",
    "test_eq(f(math), math.sqrt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "def compose_tfms(x, tfms, is_enc=True, reverse=False, **kwargs):\n",
    "    \"Apply all `func_nm` attribute of `tfms` on `x`, maybe in `reverse` order\"\n",
    "    if reverse: tfms = reversed(tfms)\n",
    "    for f in tfms:\n",
    "        if not is_enc: f = f.decode\n",
    "        x = f(x, **kwargs)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_int  (x):   return Int(x)\n",
    "def to_float(x):   return Float(x)\n",
    "def double  (x):   return x*2\n",
    "def half(x)->None: return x/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_compose(a, b, *fs): test_eq_type(compose_tfms(a, tfms=map(Transform,fs)), b)\n",
    "\n",
    "test_compose(1,   Int(1),   to_int)\n",
    "test_compose(1,   Float(1), to_int,to_float)\n",
    "test_compose(1,   Float(2), to_int,to_float,double)\n",
    "test_compose(2.0, 2.0,      to_int,double,half)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class A(Transform):\n",
    "    def encodes(self, x:float):  return Float(x+1)\n",
    "    def decodes(self, x): return x-1\n",
    "    \n",
    "tfms = [A(), Transform(math.sqrt)]\n",
    "t = compose_tfms(3., tfms=tfms)\n",
    "test_eq_type(t, Float(2.))\n",
    "test_eq(compose_tfms(t, tfms=tfms, is_enc=False), 1.)\n",
    "test_eq(compose_tfms(4., tfms=tfms, reverse=True), 3.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfms = [A(), Transform(math.sqrt)]\n",
    "test_eq(compose_tfms((9,3.), tfms=tfms), (3,2.))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "def mk_transform(f):\n",
    "    \"Convert function `f` to `Transform` if it isn't already one\"\n",
    "    f = instantiate(f)\n",
    "    return f if isinstance(f,(Transform,Pipeline)) else Transform(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "def gather_attrs(o, k, nm):\n",
    "    \"Used in __getattr__ to collect all attrs `k` from `self.{nm}`\"\n",
    "    if k.startswith('_') or k==nm: raise AttributeError(k)\n",
    "    att = getattr(o,nm)\n",
    "    res = [t for t in att.attrgot(k) if t is not None]\n",
    "    if not res: raise AttributeError(k)\n",
    "    return res[0] if len(res)==1 else L(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "def gather_attr_names(o, nm):\n",
    "    \"Used in __dir__ to collect all attrs `k` from `self.{nm}`\"\n",
    "    return L(getattr(o,nm)).map(dir).concat().unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "class Pipeline:\n",
    "    \"A pipeline of composed (for encode/decode) transforms, setup with types\"\n",
    "    def __init__(self, funcs=None, split_idx=None):\n",
    "        self.split_idx,self.default = split_idx,None\n",
    "        if funcs is None: funcs = []\n",
    "        if isinstance(funcs, Pipeline): self.fs = funcs.fs\n",
    "        else:\n",
    "            if isinstance(funcs, Transform): funcs = [funcs]\n",
    "            self.fs = L(ifnone(funcs,[noop])).map(mk_transform).sorted(key='order')\n",
    "        for f in self.fs:\n",
    "            name = camel2snake(type(f).__name__)\n",
    "            a = getattr(self,name,None)\n",
    "            if a is not None: f = L(a)+f\n",
    "            setattr(self, name, f)\n",
    "\n",
    "    def setup(self, items=None, train_setup=False):\n",
    "        tfms = self.fs[:]\n",
    "        self.fs.clear()\n",
    "        for t in tfms: self.add(t,items, train_setup)\n",
    "\n",
    "    def add(self,ts, items=None, train_setup=False):\n",
    "        if not is_listy(ts): ts=[ts]\n",
    "        for t in ts: t.setup(items, train_setup)\n",
    "        self.fs+=ts\n",
    "        self.fs = self.fs.sorted(key='order')\n",
    "\n",
    "    def __call__(self, o): return compose_tfms(o, tfms=self.fs, split_idx=self.split_idx)\n",
    "    def __repr__(self): return f\"Pipeline: {' -> '.join([f.name for f in self.fs if f.name != 'noop'])}\"\n",
    "    def __getitem__(self,i): return self.fs[i]\n",
    "    def __setstate__(self,data): self.__dict__.update(data)\n",
    "    def __getattr__(self,k): return gather_attrs(self, k, 'fs')\n",
    "    def __dir__(self): return super().__dir__() + gather_attr_names(self, 'fs')\n",
    "\n",
    "    def decode  (self, o, full=True):\n",
    "        if full: return compose_tfms(o, tfms=self.fs, is_enc=False, reverse=True, split_idx=self.split_idx)\n",
    "        #Not full means we decode up to the point the item knows how to show itself.\n",
    "        for f in reversed(self.fs):\n",
    "            if self._is_showable(o): return o\n",
    "            o = f.decode(o, split_idx=self.split_idx)\n",
    "        return o\n",
    "\n",
    "    def show(self, o, ctx=None, **kwargs):\n",
    "        o = self.decode(o, full=False)\n",
    "        o1 = (o,) if not _is_tuple(o) else o\n",
    "        if hasattr(o, 'show'): ctx = o.show(ctx=ctx, **kwargs)\n",
    "        else:\n",
    "            for o_ in o1:\n",
    "                if hasattr(o_, 'show'): ctx = o_.show(ctx=ctx, **kwargs)\n",
    "        return ctx\n",
    "\n",
    "    def _is_showable(self, o):\n",
    "        if hasattr(o, 'show'): return True\n",
    "        if _is_tuple(o): return all(hasattr(o_, 'show') for o_ in o)\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_docs(Pipeline,\n",
    "         __call__=\"Compose `__call__` of all `fs` on `o`\",\n",
    "         decode=\"Compose `decode` of all `fs` on `o`\",\n",
    "         show=\"Show `o`, a single item from a tuple, decoding as needed\",\n",
    "         add=\"Add transforms `ts`\",\n",
    "         setup=\"Call each tfm's `setup` in order\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Pipeline` is a wrapper for `compose_tfms`. You can pass instances of `Transform` or regular functions in `funcs`, the `Pipeline` will wrap them all in `Transform` (and instantiate them if needed) during the initialization. It handles the transform `setup` by adding them one at a time and calling setup on each, goes through them in order in `__call__` or `decode` and can `show` an object by applying decoding the transforms up until the point it gets an object that knows how to show itself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Empty pipeline is noop\n",
    "pipe = Pipeline()\n",
    "test_eq(pipe(1), 1)\n",
    "test_eq(pipe((1,)), (1,))\n",
    "# Check pickle works\n",
    "assert pickle.loads(pickle.dumps(pipe))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class IntFloatTfm(Transform):\n",
    "    def encodes(self, x):  return Int(x)\n",
    "    def decodes(self, x):  return Float(x)\n",
    "    foo=1\n",
    "\n",
    "int_tfm=IntFloatTfm()\n",
    "\n",
    "def neg(x): return -x\n",
    "neg_tfm = Transform(neg, neg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline([neg_tfm, int_tfm])\n",
    "\n",
    "start = 2.0\n",
    "t = pipe(start)\n",
    "test_eq_type(t, Int(-2))\n",
    "test_eq_type(pipe.decode(t), Float(start))\n",
    "test_stdout(lambda:pipe.show(t), '-2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline([neg_tfm, int_tfm])\n",
    "t = pipe(start)\n",
    "test_stdout(lambda:pipe.show(pipe((1.,2.))), '-1\\n-2')\n",
    "test_eq(pipe.foo, 1)\n",
    "assert 'foo' in dir(pipe)\n",
    "assert 'int_float_tfm' in dir(pipe)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can add a single transform or multiple transforms `ts` using `Pipeline.add`. Transforms will be ordered by `Transform.order`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline([neg_tfm, int_tfm])\n",
    "class SqrtTfm(Transform):\n",
    "    order=-1\n",
    "    def encodes(self, x): \n",
    "        return x**(.5)\n",
    "    def decodes(self, x): return x**2\n",
    "pipe.add(SqrtTfm())\n",
    "test_eq(pipe(4),-2)\n",
    "test_eq(pipe.decode(-2),4)\n",
    "pipe.add([SqrtTfm(),SqrtTfm()])\n",
    "test_eq(pipe(256),-2)\n",
    "test_eq(pipe.decode(-2),256)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transforms are available as attributes named with the snake_case version of the names of their types. Attributes in transforms can be directly accessed as attributes of the pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_eq(pipe.int_float_tfm, int_tfm)\n",
    "test_eq(pipe.foo, 1)\n",
    "\n",
    "pipe = Pipeline([int_tfm, int_tfm])\n",
    "pipe.int_float_tfm\n",
    "test_eq(pipe.int_float_tfm[0], int_tfm)\n",
    "test_eq(pipe.foo, [1,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check opposite order\n",
    "pipe = Pipeline([int_tfm,neg_tfm])\n",
    "t = pipe(start)\n",
    "test_eq(t, -2)\n",
    "test_stdout(lambda:pipe.show(t), '-2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class A(Transform):\n",
    "    def encodes(self, x):  return int(x)\n",
    "    def decodes(self, x):  return Float(x)\n",
    "\n",
    "pipe = Pipeline([neg_tfm, A])\n",
    "t = pipe(start)\n",
    "test_eq_type(t, -2)\n",
    "test_eq_type(pipe.decode(t), Float(start))\n",
    "test_stdout(lambda:pipe.show(t), '-2.0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s2 = (1,2)\n",
    "pipe = Pipeline([neg_tfm, A])\n",
    "t = pipe(s2)\n",
    "test_eq_type(t, (-1,-2))\n",
    "test_eq_type(pipe.decode(t), (Float(1.),Float(2.)))\n",
    "test_stdout(lambda:pipe.show(t), '-1.0\\n-2.0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ArrayImage(ndarray):\n",
    "    _show_args = {'cmap':'viridis'}\n",
    "    def __new__(cls, x, *args, **kwargs):\n",
    "        if isinstance(x,tuple): super().__new__(cls, x, *args, **kwargs)\n",
    "        if args or kwargs: raise RuntimeError('Unknown array init args')\n",
    "        if not isinstance(x,ndarray): x = array(x)\n",
    "        return x.view(cls)\n",
    "    \n",
    "    def show(self, ctx=None, figsize=None, **kwargs):\n",
    "        if ctx is None: _,ctx = plt.subplots(figsize=figsize)\n",
    "        ctx.imshow(im, **{**self._show_args, **kwargs})\n",
    "        ctx.axis('off')\n",
    "        return ctx\n",
    "    \n",
    "im = Image.open(TEST_IMAGE)\n",
    "im_t = ArrayImage(im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f1(x:ArrayImage): return -x\n",
    "def f2(x): return Image.open(x).resize((128,128))\n",
    "def f3(x:Image.Image): return(ArrayImage(array(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline([f2,f3,f1])\n",
    "t = pipe(TEST_IMAGE)\n",
    "test_eq(type(t), ArrayImage)\n",
    "test_eq(t, -array(f3(f2(TEST_IMAGE))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline([f2,f3])\n",
    "t = pipe(TEST_IMAGE)\n",
    "ax = pipe.show(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test_fig_exists(ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check filtering is properly applied\n",
    "add1 = B()\n",
    "add1.split_idx = 1\n",
    "pipe = Pipeline([neg_tfm, A(), add1])\n",
    "test_eq(pipe(start), -2)\n",
    "pipe.split_idx=1\n",
    "test_eq(pipe(start), -1)\n",
    "pipe.split_idx=0\n",
    "test_eq(pipe(start), -2)\n",
    "for t in [None, 0, 1]:\n",
    "    pipe.split_idx=t\n",
    "    test_eq(pipe.decode(pipe(start)), start)\n",
    "    test_stdout(lambda: pipe.show(pipe(start)), \"-2.0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def neg(x): return -x\n",
    "test_eq(type(mk_transform(neg)), Transform)\n",
    "test_eq(type(mk_transform(math.sqrt)), Transform)\n",
    "test_eq(type(mk_transform(lambda a:a*2)), Transform)\n",
    "test_eq(type(mk_transform(Pipeline([neg]))), Pipeline)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: method examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(Pipeline.__call__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(Pipeline.decode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(Pipeline.setup)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "During the setup, the `Pipeline` starts with no transform and adds them one at a time, so that during its setup, each transform gets the items processed up to its point and not after."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|hide\n",
    "#Test is with TfmdList"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|hide\n",
    "#|eval: false\n",
    "from nbdev import nbdev_export\n",
    "nbdev_export()"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "split_at_heading": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
