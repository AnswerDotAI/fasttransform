[
  {
    "objectID": "test_quantum.html",
    "href": "test_quantum.html",
    "title": "Example: quantum circuits",
    "section": "",
    "text": "This example is adapted from a blogpost by Carlo Lepelaars and originally appeared on his personal website. It is reposted here with permission.\nimport numpy as np\nfrom numpy.testing import assert_almost_equal\nfrom fasttransform import Transform, Pipeline",
    "crumbs": [
      "Example: quantum circuits"
    ]
  },
  {
    "objectID": "test_quantum.html#transform",
    "href": "test_quantum.html#transform",
    "title": "Example: quantum circuits",
    "section": "Transform",
    "text": "Transform\nTransform is a fundamental building block to manipulate data in Python. While extremely simple to use, it is also flexible. Transforms can be set up to change behavior based on the input type, also called type dispatch. Transforms can also be made reversible. Keep this reversibility in mind for the quantum part later! Here is a simple example of a Transform that can square a number and take square root as reverse:\n\nclass S(Transform):\n    def encodes(self, x): return x ** 2\n    def decodes(self, x): return x ** 0.5\n            \nassert S()(10) == 100\nassert S().decode(100) == 10\nassert S().decode(S()(10)) == 10\n\nA Transform with only encode can be defined even simpler with a lambda function. By default, decode returns its input (i.e. does nothing / “no-op”):\n\nsquare = Transform(lambda x: x ** 2)\nassert square(10) == 100\nassert square.decode(100) == 100\n\nTransform can also be used as a decorator to turn a function into a Transform:\n\n@Transform\ndef square(x): return x ** 2\nsquare(10) # 100\ntype(square) # &lt;class 'fastcore.transform.Transform'&gt;\n\nfasttransform.transform.Transform\n\n\nA powerful feature of Transform is type dispatch:\n\nclass MultiS(Transform):\n    def encodes(self, x: int | float | complex | tuple): return x**2\n    def encodes(self, x: list): return [x**2 for x in x]\n    def decodes(self, x: int | float | complex | tuple): return x**0.5\n    def decodes(self, x: list): return [x**0.5 for x in x]\n\nms = MultiS()\nms\n\nMultiS(enc:2,dec:2)\n\n\n\n# Lists\n# By default, Transform processes lists as a whole\n# 2nd encodes method is called\nassert ms([1, 2, 3]) == [1, 4, 9]\n\n\n# 2nd decodes method is called\nassert ms.decode([1, 4, 9]) == [1.0, 2.0, 3.0]\n\n\n# Tuples\n# By default, Transform processes tuples elementwise\n# 1st decodes method is called\nassert ms((1, 2, 3)) == (1, 4, 9)\n\n\n# 1st decodes method is called\nassert ms.decode((1, 4, 9)) == (1.0, 2.0, 3.0)\n\n\n# Complex numbers\n# 1st encodes method is called on complex number\nassert ms(10.0j) == (-100+0j)\n\n\n# 1st decodes method is called on complex number\nassert ms.decode(ms(10.0j)) == (6.123233995736766e-16+10j)\n\nTransform automatically routes input to the corresponding method based on the input type. Transform will operate on lists as a whole, while tuples are processed elementwise. Processing lists and arrays as one object is a common use case in data science, for example if we are processing batches of images (3D arrays) for machine learning. If you want a Transform that also transforms tuples as a whole, use ItemTransform. To support inplace transforms use InplaceTransform.",
    "crumbs": [
      "Example: quantum circuits"
    ]
  },
  {
    "objectID": "test_quantum.html#pipeline",
    "href": "test_quantum.html#pipeline",
    "title": "Example: quantum circuits",
    "section": "Pipeline",
    "text": "Pipeline\nNow that we have a firm understanding of Transform, Pipeline can be used to chain them together:\n\nclass S(Transform):\n    \"Square a number. Reverse is square root.\"\n    def encodes(self, x): return x ** 2\n    def decodes(self, x): return x ** 0.5\n    \nclass A(Transform):\n    \"Add 1. Reverse is subtract 1.\"\n    def encodes(self, x): return x + 1\n    def decodes(self, x): return x - 1\n\npipe = Pipeline([S(), A()])\nassert pipe(10) == 101 # 10**2 + 1 = 101\nassert pipe.decode(10) == 3.0 # (10 - 1)**0.5 = 3.0\nassert pipe.decode(pipe(10)) == 10 # (10**2 + 1 - 1)**0.5 = 10\n\nI hope you appreciate the simplicity of Transform and Pipeline. This year I’ve been working on an open-source library for quantum computing that connects several quantum computing frameworks and standards (For example, Qiskit, PennyLane and OpenQASM. At the base of it lies numpy. To generalize quantum circuits I tried using scikit-learn’s Pipeline functionality. Unfortunately this led to a lot of boilerplate code and unnecessary features. fastcore offers a more elegant and promising solution for the use case of constructing quantum circuits, which we will explore in the next section.",
    "crumbs": [
      "Example: quantum circuits"
    ]
  },
  {
    "objectID": "test_quantum.html#quantum",
    "href": "test_quantum.html#quantum",
    "title": "Example: quantum circuits",
    "section": "Quantum",
    "text": "Quantum\nQuantum computing processes can be simulated on classical computers by transforming a statevector (i.e. list of complex numbers) through a series of reversible quantum logic gates (i.e. matrix of complex numbers). The state and gates are subject to constraints, but the basic operation is (reversible) vector-matrix multiplication. This is a perfect use case for fastcore’s Transform and Pipeline. To illustrate this point we will start with manipulating a single qubit using Transform.\n\nSingle Qubit\nA statevector contains 2 complex numbers which gives us the likelihood of obtaining a \\(0\\) or \\(1\\). This is called a superposition between \\(0\\) and \\(1\\). The numbers in the vector are called probability amplitudes and can be converted to probabilities by computing \\(|x|^2\\) (i.e. the absolute value squared), where \\(x\\) is the statevector. Probabilities must always sum to \\(1\\), so a valid qubit state \\([\\alpha, \\beta]\\) must have \\(|\\alpha|^2 + |\\beta|^2 = 1\\).\nA shortcut used for writing quantum states is Dirac notation. For example \\(|0\\rangle=[1, 0]^T\\) (i.e. always 0) and \\(|1\\rangle=[0, 1]^T\\) (i.e. always 1). Other valid single qubit states include \\(\\frac{1}{\\sqrt{2}}(|0\\rangle + |1\\rangle) = \\begin{bmatrix} \\frac{1}{\\sqrt{2}} \\frac{1}{\\sqrt{2}} \\end{bmatrix}^T\\) for a perfectly equal superposition and \\(\\frac{1+i}{2}|0\\rangle + \\frac{1-i}{2}|1\\rangle = \\begin{bmatrix} \\frac{1+i}{2} \\frac{1-i}{2} \\end{bmatrix}^T\\) for a superposition of both the real and complex parts.\nUsing Transform we can easily define quantum logic gates. We define a base Transform that can do vector-matrix multiplication in a reversible way and implement common quantum gates. The I (identity) gate does nothing, the X (NOT) gate flips the qubit from \\(|0\\rangle\\) to \\(|1\\rangle\\) and vice versa. The Hadamard gate turns a qubit into superposition (i.e. turn \\(|0\\rangle\\) into \\(\\frac{1}{\\sqrt{2}}(|0\\rangle + |1\\rangle)\\)).\n\nclass _Q(Transform):\n    \"Base transform for quantum gates\"\n    def encodes(self, x): return x @ self.gate\n    def decodes(self, x): return x @ self.gate.conj().T\n                     \nclass I(_Q):\n    \"Identity gate. Does nothing.\"\n    gate = np.array([[1, 0], \n                     [0, 1]])\n    \nclass X(_Q):\n    \"X (NOT) gate. Flips from |0&gt; to |1&gt; and vice versa.\"\n    gate = np.array([[0, 1], \n                     [1, 0]])\n    \nclass H(_Q):\n    \"Hadamard (Superposition) gate. Turns a qubit into a superposition.\"\n    gate = np.array([[1, 1], \n                     [1, -1]]) / np.sqrt(2)\n\nThis allows us to easily play with quantum gates:\n\nzero_state = [1+0j, 0+0j] # Basis state |0&gt;\nsuperposition_state = np.array([0.5+0.5j, 0.5-0.5j])  # Complex superposition\n\n\n# Identity operation\ni = I() \nassert_almost_equal(i(zero_state), np.array([1.+0.j, 0.+0.j])) # (|0&gt;)\nassert_almost_equal(i.decode(zero_state), np.array([1.+0.j, 0.+0.j]))  # (|0&gt;)\n\n\n# X (NOT) operation \nx = X()\nassert_almost_equal(x(zero_state), np.array([0+0j, 1+0j]))  # (|1&gt;)\nassert_almost_equal(x.decode(x(zero_state)), np.array([1.+0.j, 0.+0.j]))  # (|0&gt;)\nassert_almost_equal(x(superposition_state), np.array([0.5-0.5j, 0.5+0.5j]))  # (flips sign of complex part)\n\n\n# Hadamard gate tests\nh = H()\nassert_almost_equal(h(zero_state), np.array([0.707+0.j, 0.707+0.j]), decimal=3)  # (superposition)\nassert_almost_equal(h(superposition_state), np.array([0.707+0.j, 0.+0.707j]), decimal=3)  # (phase state)\nassert_almost_equal(h.decode(h(superposition_state)), np.array([0.5+0.5j, 0.5-0.5j]))  # (complex superposition)\n\nI hope this gives you an appreciation for the simplicity of Transform and why it works for quantum, even if the details and meaning of these operations might not be clear yet. If you are interested in learning about quantum computing I highly recommend reading the amazing educational material on quantum.country. A great quantum textbook is “Quantum Computing and Quantum Information” by Michael Nielsen and Isaac Chuang.\nAnother essential component of quantum is measurement. This transforms the quantum state into a probability distribution we can sample from. Note that these operations are not reversible. This is because after measurement, a quantum state collapses:\n\nclass M(Transform):\n    \"Turn a quantum statevector into a probability distribution\"\n    def encodes(self, x): return np.abs(x)**2\n    def decodes(self, x): return NotImplementedError(\"No inverse exists for absolute value.\")\n\nclass Samp(Transform):\n    \"Sample from a probability distribution\"\n    def encodes(self, x): return format(np.random.choice(len(x), p=x), f'0{int(np.log2(len(x)))}b')\n    def decodes(self, x): return NotImplementedError(\"Sampling is not reversible.\")\n\nm = M()\nsamp = Samp()\n\n\n# Sampling from zero state (|0&gt;)\nzero_state = [1+0j, 0+0j]\nmzs = m(zero_state) # Transforms [1+0j, 0+0j] -&gt; [1, 0]\n\nassert_almost_equal(mzs, np.array([1+0j,0+0j]))                     \nassert samp(mzs) == '0'\n\n\n# Sampling from equal superposition\nequal_superposition = [0.707, 0.707]\nmes = m(equal_superposition) # Transforms [0.707, 0.707] -&gt; [0.5, 0.5] (A coin flip. i.e. Bernoulli distribution))\n\n\nmes = mes / mes.sum()  # not in original blog but needed as otherwises numers dont add to 1 because of rounding\nassert_almost_equal(mes, np.array([0.5,0.5]))\nassert samp(mes) in '01' # 0 or 1 with equal probability\n\n\n# Sampling from complex superposition\ncomplex_superposition = [0.5+0.5j, 0.5-0.5j]\nmcs = m(complex_superposition) # Transforms [0.5+0.5j, 0.5-0.5j] -&gt; [0.5, 0.5] (A coin flip. i.e. Bernoulli distribution)\nassert_almost_equal(mcs, np.array([0.5,0.5]))\n\n\nassert samp(mcs) in '01'  # Result is 0 or 1 with equal probability\n\nWe can now build a full quantum circuit using Pipeline. Note that a quantum pipeline is only reversible if it does not include measurement or sampling:\n\nqc = Pipeline([X(), H(), I(), M(), Samp()])\n# X transforms [1, 0] -&gt; [0, 1]\n# H transforms [0, 1] -&gt; [0.707+0j, -0.707+0j]\n# I transforms [0.707+0j, -0.707+0j] -&gt; [0.707+0j, -0.707+0j]\n# M transforms [0.707+0j, -0.707+0j] -&gt; [0.5, 0.5]\n# Samp samples from random distribution [0.5, 0.5]\nassert qc(zero_state) in '01' # 0 or 1 with equal probability\n\n\n\nMulti Qubit\nEven though we only discussed single qubit cases we can the potential of Transform for quantum. It gets even more powerful if we start working with multiple qubits. The representation of a quantum state on a classical computer grows exponentially with each qubit, because each qubit can be entangled with others. We therefore need a matrix of \\(2^n\\) x \\(2^n\\) to represent a transformation of \\(n\\) qubits. The statevector for \\(n\\) qubits contains \\(2^n\\) complex numbers. Single qubit gates can be combined through the Tensor (Kronecker) product, which we handle in Concat:\n\nclass Concat(Transform):\n    \"Combine single qubit gates into a multi-qubit gate\"\n    def __init__(self, gates): self.gates = gates\n    # Concatenate 2 or more gates\n    def encodes(self, x): return x @ np.kron(*[g.gate for g in self.gates])\n    # Reverse propagation for all gates\n    def decodes(self, x):\n        for g in reversed(self.gates): x = x @ np.kron(g.gate.conj().T, np.eye(len(x) // g.gate.shape[0]))\n        return x\n\nBy concatenating single qubit gates we can construct multi-qubit circuits, while keeping the code extremely simple. However, some gates are fundamentally multi-qubit and cannot be constructed from single qubits. One example is the Controlled NOT (CNOT) gate, which flips the 2nd qubit from \\(|0\\rangle\\) to \\(|1\\rangle\\) based on the value of the 1st qubit. When we combine Hadamard on the 1st qubit and a CNOT gate we get the well known Bell state. This is a classic example of fully entangling qubits where we obtain \\(00\\) or \\(11\\) with equal probability.\n\nclass CNOT(_Q):\n    \"Controlled NOT gate\"\n    def __init__(self): self.gate = np.array([[1, 0, 0, 0], \n                                              [0, 1, 0, 0], \n                                              [0, 0, 0, 1], \n                                              [0, 0, 1, 0]])\n                     \ntwo_qubit_zero_state = np.array([1+0j, 0+0j, 0+0j, 0+0j]) # |00&gt;\nqc = Pipeline([Concat([H(), I()]), CNOT(), M(), Samp()])\n# Concat([H(), I()]) transforms [1, 0, 0, 0] -&gt; [0.707, 0, 0.707, 0]\n# CNOT() transforms [0.707, 0, 0.707, 0] -&gt; [0.707, 0, 0, 0.707]\n# M() transforms [0.707, 0, 0, 0.707] -&gt; [0.5, 0, 0, 0.5]\n# Samp() samples from [0.5, 0, 0, 0.5] (50% chance at 00 and 50% chance at 3, which is 11 in binary)\nassert qc(two_qubit_zero_state) in ('00','11') # 00 or 11 with equal probability\n\nThese techniques can be used to simulate and analyze more complicated multi-qubit circuits. The nice thing about building quantum circuits like this is that we can analyze every step and get a good understanding of what is happening. It also allows us to precisely explore techniques like quantum error correction. However, for large scale quantum circuits the matrices are huge and real quantum computers are needed to do the computation. Real quantum computers directly leverage properties of quantum mechanics like entanglement, superposition and interference. These are things that a classical computer can simulate, but cannot natively perform like a real quantum computer. Exploiting quantum properties can result in potentially exponential speedups. For more information on where quantum computers excel check out Ronald de Wolf’s great paper on “The Potential Impact of Quantum Computers on Society (2017). This paper has stood the test of time even though new breakthroughs have been achieved.m",
    "crumbs": [
      "Example: quantum circuits"
    ]
  },
  {
    "objectID": "test_quantum.html#closing",
    "href": "test_quantum.html#closing",
    "title": "Example: quantum circuits",
    "section": "Closing",
    "text": "Closing\nIf you made it all the way to the end, congratulations! I salute you! 🫡 Having an understanding of both advanced Python and quantum computing is a rare skillset. If you are interested in this intersection you might be interested in exploring Quantum Machine Learning. This field combines the optimization we often see in data science and machine learning with quantum computing. If this piques your interest, one of the best textbooks around is “Machine Learning with Quantum Computers by Maria Schuld and Francesco Petruccione”.",
    "crumbs": [
      "Example: quantum circuits"
    ]
  },
  {
    "objectID": "test_quantum.html#learning-resources",
    "href": "test_quantum.html#learning-resources",
    "title": "Example: quantum circuits",
    "section": "Learning resources",
    "text": "Learning resources\nIf you are interested in learning more about quantum, I recommend the following resources:\n\nOnline Resources\n\nQuantum Country - Quantum Education Essays\nIBM Quantum Learning Platform\nPennyLane Quantum Learning Platform\nq4p - Quantum Computing for (Python) Programmers (by Carlo Lepelaars)\nPaper: The Potential Impact of Quantum Computers on Society (2017) by Ronald de Wolf\n\n\n\nBooks\n\nQuantum Computation and Quantum Information (Nielsen & Chuang)\nMachine Learning with Quantum Computers (Schuld & Petruccione)\nQuantum Mechanics: The Theoretical Minimum (Susskind)\nModern Quantum Mechanics (Sakurai)\n\n\n\nYouTube\n\nPlaylist - Introduction to Quantum information Science (Artur Ekert)\nPlaylist - Quantum Machine Learning (Peter Wittek)\nPlaylist - Quantum Paradoxes (Maria Violaris)\nPlaylist - The History of Quantum Computing (Interviews)\nPlaylist - Maths of Quantum Mechanics\nChannel - Looking Glass Universe\nVideo - The Map of Quantum Computing\nVideo - Logic Gates Rotate Qubits (Josh’s Channel)\nVideo - How Quantum Entanglement Works\nVideo - Interpretations of Quantum Mechanics",
    "crumbs": [
      "Example: quantum circuits"
    ]
  },
  {
    "objectID": "fastcore_migration_guide.html",
    "href": "fastcore_migration_guide.html",
    "title": "Fastcore migration guide",
    "section": "",
    "text": "If you’re using fastai, there’s nothing you need to do - these changes will be included in future fastai releases and your existing code will continue to work as before.",
    "crumbs": [
      "Fastcore migration guide"
    ]
  },
  {
    "objectID": "fastcore_migration_guide.html#fastai-users",
    "href": "fastcore_migration_guide.html#fastai-users",
    "title": "Fastcore migration guide",
    "section": "",
    "text": "If you’re using fastai, there’s nothing you need to do - these changes will be included in future fastai releases and your existing code will continue to work as before.",
    "crumbs": [
      "Fastcore migration guide"
    ]
  },
  {
    "objectID": "fastcore_migration_guide.html#fastcore-dispatch-users",
    "href": "fastcore_migration_guide.html#fastcore-dispatch-users",
    "title": "Fastcore migration guide",
    "section": "Fastcore dispatch users",
    "text": "Fastcore dispatch users\nFastcore’s type dispatch system is being replaced with Plum, a more robust multiple dispatch library. This section covers how to update your code that uses @typedispatch or TypeDispatch.\n\nInstall plum:\npip install plum-dispatch\n\n\nSimple decorator migration\nFor most usecases switching to plum is as easy as switching out fastcore’s typedispatch for plum’s dispatch.\nBefore:\n\nfrom fastcore.dispatch import typedispatch\n\n@typedispatch \ndef proc_fc(x: int): return x + 1\n\n@typedispatch\ndef proc_fc(x: float): return x * 2\n\nAfter:\n\nfrom plum import dispatch\n\n@dispatch \ndef proc_pl(x: int): return x + 1\n\n@dispatch\ndef proc_pl(x: float): return x * 2\n\n\n\nConverting TypeDispatch to Plum Function\nIf you’re using TypeDispatch directly, you’ll need to use Plum’s Function class instead.\nThe key differences are:\n\nInitialization uses Function() instead of TypeDispatch()\nMethods are added using .register() or .dispatch()\nFunction inspection uses .methods instead of print()\n\n\nInitialization\n\n# setup\nimport numbers\n\ndef f2(x:int, y:float)-&gt;float: return x+y               #int and float for 2nd arg\ndef f_nin(x:numbers.Integral)-&gt;int: return x+1          #integral numeric\ndef f_ni2(x:int): return x                              #integer\ndef f_fl(x:float)-&gt;float: return x                      #float\ndef f_bll(x:bool|list)-&gt;bool|list: return x             #bool or list\ndef f_num(x:numbers.Number)-&gt;numbers.Number: return x   #Number (root of numerics)\n\nfs = [\n    f2, \n    f_nin, \n    f_ni2, \n    f_fl,\n    f_bll, \n    f_num\n]\n\nBefore:\n\nfrom fastcore.dispatch import TypeDispatch\nt_fc = TypeDispatch(fs)\nt_fc\n\n(bool,object) -&gt; f_bll\n(int,float) -&gt; f2\n(int,object) -&gt; f_ni2\n(Integral,object) -&gt; f_nin\n(float,object) -&gt; f_fl\n(list,object) -&gt; f_bll\n(Number,object) -&gt; f_num\n\n\nAfter:\n\nfrom plum import Function\n\nt_pl = Function(f2)\nfor f in fs: t_pl.register(f)\nlen(t_pl.methods)\n\n6\n\n\n\n\nAdding new functions to an initialized TypeDispatch/Function\nBefore:\n\nt_fc.add(lambda x: x**2)\nt_fc\n\n(bool,object) -&gt; f_bll\n(int,float) -&gt; f2\n(int,object) -&gt; f_ni2\n(Integral,object) -&gt; f_nin\n(float,object) -&gt; f_fl\n(list,object) -&gt; f_bll\n(Number,object) -&gt; f_num\n(object,object) -&gt; &lt;lambda&gt;\n\n\nAfter:\n\nt_pl.register(lambda x: x**2)  # or t_pl.dispatch(lambda x: x**2)\nt_pl.methods\n\n\n\n\nList of 7 method(s):\n    [0] f2(x: int, y: float) -&gt; float                                                                              \n        &lt;function f2 at 0x10be6df80&gt; @                                                                             \n    /var/folders/0h/5ktbjhg17ns6j8zgdsgvzvy80000gn/T/ipykernel_14825/891647847.py:4                                \n    [1] f2(x: numbers.Integral) -&gt; int                                                                             \n        &lt;function f_nin at 0x10be6dee0&gt; @                                                                          \n    /var/folders/0h/5ktbjhg17ns6j8zgdsgvzvy80000gn/T/ipykernel_14825/891647847.py:5                                \n    [2] f2(x: int)                                                                                                 \n        &lt;function f_ni2 at 0x10be6e020&gt; @                                                                          \n    /var/folders/0h/5ktbjhg17ns6j8zgdsgvzvy80000gn/T/ipykernel_14825/891647847.py:6                                \n    [3] f2(x: float) -&gt; float                                                                                      \n        &lt;function f_fl at 0x10be6e0c0&gt; @                                                                           \n    /var/folders/0h/5ktbjhg17ns6j8zgdsgvzvy80000gn/T/ipykernel_14825/891647847.py:7                                \n    [4] f2(x: bool | list) -&gt; bool | list                                                                          \n        &lt;function f_bll at 0x10be6e160&gt; @                                                                          \n    /var/folders/0h/5ktbjhg17ns6j8zgdsgvzvy80000gn/T/ipykernel_14825/891647847.py:8                                \n    [5] f2(x: numbers.Number) -&gt; numbers.Number                                                                    \n        &lt;function f_num at 0x10be6e200&gt; @                                                                          \n    /var/folders/0h/5ktbjhg17ns6j8zgdsgvzvy80000gn/T/ipykernel_14825/891647847.py:9                                \n    [6] f2(x: Any)                                                                                                 \n        &lt;function &lt;lambda&gt; at 0x10be85260&gt; @                                                                       \n    /var/folders/0h/5ktbjhg17ns6j8zgdsgvzvy80000gn/T/ipykernel_14825/2634702974.py:1                               \n\n\n\n\n\nCombining multiple instances of TypeDispatch/Function\nFastcore provided a way to initialize TypeDispatch with pre-existing TypeDispatch objects as its base(s).\nBefore:\n\ndef f_str(x:str): return x+'1'\n\n\nt_fc2 = TypeDispatch(f_str, bases=t_fc)\nt_fc2\n\n(str,object) -&gt; f_str\n(bool,object) -&gt; f_bll\n(int,float) -&gt; f2\n(int,object) -&gt; f_ni2\n(Integral,object) -&gt; f_nin\n(float,object) -&gt; f_fl\n(list,object) -&gt; f_bll\n(Number,object) -&gt; f_num\n(object,object) -&gt; &lt;lambda&gt;\n\n\nPlum does not provide this feature directly. But we’ve written a function to help you accomplish a similar result.\nAfter:\n\nfrom fasttransform.transform import _merge_funcs\n\nt_pl_new = Function(f_str).dispatch(f_str)\nt_pl2 = _merge_funcs(t_pl_new, t_pl)\nt_pl2.methods\n\n\n\n\nList of 8 method(s):\n    [0] f_str(x: int, y: float) -&gt; float                                                                           \n        &lt;function f2 at 0x10be6df80&gt; @                                                                             \n    /var/folders/0h/5ktbjhg17ns6j8zgdsgvzvy80000gn/T/ipykernel_14825/891647847.py:4                                \n    [1] f_str(x: numbers.Integral) -&gt; int                                                                          \n        &lt;function f_nin at 0x10be6dee0&gt; @                                                                          \n    /var/folders/0h/5ktbjhg17ns6j8zgdsgvzvy80000gn/T/ipykernel_14825/891647847.py:5                                \n    [2] f_str(x: int)                                                                                              \n        &lt;function f_ni2 at 0x10be6e020&gt; @                                                                          \n    /var/folders/0h/5ktbjhg17ns6j8zgdsgvzvy80000gn/T/ipykernel_14825/891647847.py:6                                \n    [3] f_str(x: float) -&gt; float                                                                                   \n        &lt;function f_fl at 0x10be6e0c0&gt; @                                                                           \n    /var/folders/0h/5ktbjhg17ns6j8zgdsgvzvy80000gn/T/ipykernel_14825/891647847.py:7                                \n    [4] f_str(x: bool | list) -&gt; bool | list                                                                       \n        &lt;function f_bll at 0x10be6e160&gt; @                                                                          \n    /var/folders/0h/5ktbjhg17ns6j8zgdsgvzvy80000gn/T/ipykernel_14825/891647847.py:8                                \n    [5] f_str(x: numbers.Number) -&gt; numbers.Number                                                                 \n        &lt;function f_num at 0x10be6e200&gt; @                                                                          \n    /var/folders/0h/5ktbjhg17ns6j8zgdsgvzvy80000gn/T/ipykernel_14825/891647847.py:9                                \n    [6] f_str(x: Any)                                                                                              \n        &lt;function &lt;lambda&gt; at 0x10be85260&gt; @                                                                       \n    /var/folders/0h/5ktbjhg17ns6j8zgdsgvzvy80000gn/T/ipykernel_14825/2634702974.py:1                               \n    [7] f_str(x: str)                                                                                              \n        &lt;function f_str at 0x10be85ee0&gt; @                                                                          \n    /var/folders/0h/5ktbjhg17ns6j8zgdsgvzvy80000gn/T/ipykernel_14825/3062264994.py:1                               \n\n\n\n\n\nObtain the raw function and return type for given arg types\nIf you wanted to retrieve the raw function that matches given runtime input types. Then with TypeDispatch you could use the __getitem__ method.\nBefore:\n\nt_fc[int]\n\n&lt;function __main__.f_ni2(x: int)&gt;\n\n\nIf you wanted to retrieve that raw function’s return type then you can use the .returns method.\nBefore:\n\nt_fc.returns(5)\n\nPlum’s Function does not provided the exact same functionality. But you can pass arguments to .resolve_method or ._resolve_method_with_cache method to find the matching raw function and it’s return type.\nAfter:\n\nraw_func, ret_type = t_pl.resolve_method((5,))\nprint(raw_func)\nprint(ret_type)\n\n&lt;function f_ni2&gt;\ntyping.Any\n\n\nor the cached version:\n\nraw_func, ret_type = t_pl._resolve_method_with_cache((5,))\nprint(raw_func)\nprint(ret_type)\n\n&lt;function f_ni2&gt;\ntyping.Any\n\n\n\n\n\nBreaking Change: Ambiguous Type Matching\nA key behavioral difference in Plum is how it handles ambiguous type matches:\n\nFastcore: Silently uses the last defined function when multiple matches exist\nPlum: Raises an AmbiguousLookupError to prevent unexpected behavior\n\nExample:\n\n@typedispatch\ndef f2_fc(x:int|float): return x+2\n@typedispatch\ndef f2_fc(x:int|str): return x*3\n\nf2_fc(5)\n\n15\n\n\nWhile plum will raise an AmbiguousLookupError.\n\nfrom plum import AmbiguousLookupError\n\n@dispatch\ndef f2_pl(x:int|float): return x+2\n@dispatch\ndef f2_pl(x:int|str): return x*3\n\ntry: f2_pl(5)\nexcept AmbiguousLookupError: print(\"Caught expected AmbiguousLookupError\")\n\nCaught expected AmbiguousLookupError",
    "crumbs": [
      "Fastcore migration guide"
    ]
  },
  {
    "objectID": "fastcore_migration_guide.html#moving-from-fastcore-to-fasttransform",
    "href": "fastcore_migration_guide.html#moving-from-fastcore-to-fasttransform",
    "title": "Fastcore migration guide",
    "section": "Moving from fastcore to fasttransform",
    "text": "Moving from fastcore to fasttransform\nIf you’re using Transform or Pipeline, follow these steps:\n\ninstall fasttransform\n\nInstall the new package:\npip install fasttransform\n\n\n\nUpdate imports\n# Before\nfrom fastcore.transform import Transform, Pipeline\n\n# After\nfrom fasttransform import Transform, Pipeline\n\n\n\nInitializing Transform\nIn fasttransform, you can now define multiple encode/decode methods either through subclassing (like before) or directly:\n\n# Before (subclassing required)\nfrom fastcore.transform import Transform as FCTransform\n\nclass MyTransform(FCTransform):\n    def encodes(self, x:int): return \"enc int!\"\n    def encodes(self, x:str): return \"enc str!\"\n    \n    def decodes(self, x:int): return \"dec int!\"\n    def decodes(self, x:str): return \"dec str!\"\n\nfct = MyTransform()\nfct\n\nMyTransform:\nencodes: (int,object) -&gt; encodes\n(str,object) -&gt; encodes\ndecodes: (int,object) -&gt; decodes\n(str,object) -&gt; decodes\n\n\nWhile the old behavior is still supported, you can now also do the following:\n\n# After (direct initialization possible)\nfrom fasttransform import Transform\n\ndef my_transform(x:int): return \"enc int!\"\ndef my_transform2(x:str): return \"enc str!\"\ndef my_transform_dec(x:int): return \"dec int!\"\ndef my_transform_dec2(x:str): return \"dec str!\"\n\nTransform(enc=(my_transform,my_transform2), dec=(my_transform_dec,my_transform_dec2))\n\nmy_transform(enc:2,dec:2)\n\n\n\n\nAdvanced: Custom Transform Implementation\nIf you’ve overridden internal methods like _call or _do_call in your custom Transform classes:\n\nReview the new Plum-based implementation in the source code\nUpdate your methods to work with Plum’s Function class instead of TypeDispatch\nIf you need help, create an issue",
    "crumbs": [
      "Fastcore migration guide"
    ]
  },
  {
    "objectID": "cast.html",
    "href": "cast.html",
    "title": "Cast",
    "section": "",
    "text": "from __future__ import annotations\nfrom nbdev.showdoc import *\nfrom fastcore.test import *\nfrom fastcore.nb_imports import *\nThis module contains some of fastcore.dispatch’s utility functions for type casting. We copy them over here as with fasttransform’s release those modules may be removed from fastcore.\nThe functions here have not been changed, except for retain_type, which has the same functionality but now accepts the type hints as Plum dispatch provides them instead of fastcore.dispatch’s convention.",
    "crumbs": [
      "Cast"
    ]
  },
  {
    "objectID": "cast.html#type-casting",
    "href": "cast.html#type-casting",
    "title": "Cast",
    "section": "Type casting",
    "text": "Type casting\nSome objects may have a set_meta method, such as fastai.torch_core.Tensor. When casting these to another type we want to preserve metadata.\n\nsource\n\nretain_meta\n\n retain_meta (x, res, as_copy=False)\n\nCall res.set_meta(x), if it exists\n\nsource\n\n\ndefault_set_meta\n\n default_set_meta (x, as_copy=False)\n\nCopy over _meta from x to res, if it’s missing\n\nsource\n\n\ncast\n\n cast (x, typ)\n\ncast x to type typ (may also change x inplace)\nThis works both for plain python classes…\n\nmk_class('_T1', 'a')   # mk_class is a fastai utility that constructs a class.\nclass _T2(_T1): pass\n\nt = _T1(a=1)\nt2 = cast(t, _T2)        \nassert t2 is t            # t2 refers to the same object as t\nassert isinstance(t, _T2) # t also changed in-place\nassert isinstance(t2, _T2)\n\ntest_eq_type(_T2(a=1), t2)\n\n…as well as for arrays and tensors.\n\nclass _T1(ndarray): pass\n\nt = array([1])\nt2 = cast(t, _T1)\ntest_eq(array([1]), t2)\ntest_eq(_T1, type(t2))",
    "crumbs": [
      "Cast"
    ]
  },
  {
    "objectID": "cast.html#retain-type",
    "href": "cast.html#retain-type",
    "title": "Cast",
    "section": "Retain type",
    "text": "Retain type\nRetain type is a function that’s useful for postprocessing function outputs. They are used in the Transform class.\nThe conversion priorities are as follows:\n\nthe function’s return type annotation ret_type\nif there’s no return type annotation (i.e. ret_type=Any) then it will convert back to the input’s (old) type, but only if if it was a subtype of the return value.\nif the function has return type annotation of None (ret_type=None) then no conversion will be done.\n\n\nsource\n\nretain_type\n\n retain_type (new, old, ret_type=typing.Any, as_copy=False)\n\nCast new to ret_type if given, or old’s type if new is a superclass of old. No conversion is done if ret_type=None\n\n\nReturn type annotation conversion\nWe try and convert new to the return type if it’s given.\n\nclass FS(float):\n    def __repr__(self): return f'FS({float(self)})'\n\n\ntest_eq(retain_type(1., 2., FS), FS(1.))\n\nEven if it won’t work, we’ll let the exception be raised:\n\n# Raise error if return type is not compatible with new\ntry: retain_type(\"a\", 2., FS)\nexcept ValueError as e: print(f\"Expected error: {e}\")\n\nExpected error: could not convert string to float: 'a'\n\n\n\n\nOld type conversion\nIf the return type is Any then new looks at old for conversion guidance.\n\ntest_eq(retain_type(1., FS(2.), Any), FS(1.))\n\nBut if new isn’t subclass of old, keep new:\n\ntest_eq(retain_type(FS(1.), 2.0, Any), FS(1.))\ntest_eq(retain_type(\"a\", 2.0, Any), \"a\")\n\nNo casting needed if new is already of type old. Then we return the original object.\n\nx = FS(1.)\ntest_is(retain_type(x, FS(2.), Any), x)\n\n\n\nEdge cases with None\nWe dont convert at all if None is return type annotation:\n\ntest_eq(retain_type(1., FS(2.), NoneType), 1.)\n\nNone stays None:\n\ntest_eq(retain_type(None,FS(2.), Any), None)\n\nIf old was None then we just return new.\n\ntest_eq(retain_type(FS(1.), None, Any), FS(1.))\n\n\n\nMetadata retention\nIf old has a _meta attribute, its content is passed when casting new to the type of old. In the below example, only the attribute a, but not other_attr is kept, because other_attr is not in _meta:\n\nclass _A():\n    set_meta = default_set_meta\n    def __init__(self, t): self.t=t\n\nclass _B1(_A):\n    def __init__(self, t, a=1):\n        super().__init__(t)\n        self._meta = {'a':a}\n        self.other_attr = 'Hello' # will not be kept after casting.\n        \nx = _B1(1, a=2)\nb = _A(1)\nc = retain_type(b, old=x)\ntest_eq(c._meta, {'a': 2})\nassert not getattr(c, 'other_attr', None)",
    "crumbs": [
      "Cast"
    ]
  },
  {
    "objectID": "cast.html#retain-types",
    "href": "cast.html#retain-types",
    "title": "Cast",
    "section": "Retain types",
    "text": "Retain types\nCast each item of new to type of matching item in old if it’s a superclass.\n\nsource\n\nretain_types\n\n retain_types (new, old=None, typs=None)\n\nCast each item of new to type of matching item in old if it’s a superclass\n\nclass T(tuple): pass\n\nt1,t2 = retain_types((1,(1,(1,1))), (2,T((2,T((3,4))))))\ntest_eq_type(t1, 1)\ntest_eq_type(t2, T((1,T((1,1)))))\n\nt1,t2 = retain_types((1,(1,(1,1))), typs = {tuple: [int, {T: [int, {T: [int,int]}]}]})\ntest_eq_type(t1, 1)\ntest_eq_type(t2, T((1,T((1,1)))))\n\n\nsource\n\n\nexplode_types\n\n explode_types (o)\n\nReturn the type of o, potentially in nested dictionaries for thing that are listy\n\ntest_eq(explode_types((2,T((2,T((3,4)))))), {tuple: [int, {T: [int, {T: [int,int]}]}]})",
    "crumbs": [
      "Cast"
    ]
  },
  {
    "objectID": "transform.html",
    "href": "transform.html",
    "title": "Transform",
    "section": "",
    "text": "The classes here provide functionality for creating a composition of partially reversible functions. By “partially reversible” we mean that a transform can be decoded, creating a form suitable for display. This is not necessarily identical to the original form (e.g. a transform that changes a byte tensor to a float tensor does not recreate a byte tensor when decoded, since that may lose precision, and a float tensor can be displayed already).\nClasses are also provided and for composing transforms, and mapping them over collections. Pipeline is a transform which composes several Transform, knowing how to decode them or show an encoded item.\nThe goal of this module is to replace fastcore.Transform by using the package Plum for multiple dispatch rather than the fastcore.dispatch module. Plum is a well maintained library, that provides better dispatch functionality.\ndef f1(x:int): return 'int1'\ndef f2(x:float): return 'float2'\ndef f3(x:str): return 'str3' \ndef f4(x:int): return 'int4'\n\nf = Function(f1).dispatch(f1).dispatch(f2)\ng = Function(f3).dispatch(f3).dispatch(f4)\n\nh = _merge_funcs(f,g)\ntest_eq(h(1), 'int1')\ntest_eq(h('a'), 'str3')\ntest_eq(h(1.), 'float2')\nsource",
    "crumbs": [
      "Transform"
    ]
  },
  {
    "objectID": "transform.html#return-type-casting",
    "href": "transform.html#return-type-casting",
    "title": "Transform",
    "section": "Return type casting",
    "text": "Return type casting\nWithout any intervention it is easy for operations to change types in Python. For example, FS (defined below) becomes a float after performing multiplication:\n\ntest_eq_type(FS(3.0) * 2, 6.0)\n\nThis behavior is often not desirable when performing transformations on data. Therefore, Transform will attempt to cast the output to be of the same type as the input by default. In the below example, the output will be cast to a FS type to match the type of the input:\n\nWithout type annotations\n\n@Transform\ndef f(x): return x*2\n\ntest_eq_type(f(FS(3.0)), FS(6.0))\n\nWe can optionally turn off casting by annotating the transform function with a return type of None:\n\n\nReturn type None\n\n@Transform\ndef f(x)-&gt; None: return x*2 # Same transform as above, but with a -&gt; None annotation\n\ntest_eq_type(f(FS(3.0)), 6.0)  # Casting is turned off because of -&gt; None annotation\n\nHowever, Transform will only cast output back to the input type when the input is a subclass of the output. In the below example, the input is of type FS which is not a subclass of the output which is of type str. Therefore, the output doesn’t get cast back to FS and stays as type str:\n\n@Transform\ndef f(x): return str(x)\n    \ntest_eq_type(f(Float(2.)), '2.0')\n\nTransform will attempt to convert the function output to the return type annotation.\n\n\nSpecific return types\nIf a return type annotation is given, Transform will convert it to that type:\n\n@Transform\ndef f(x)-&gt;FS: return float(x)\n\n# Output is converted to FS because its a subtype of float\ntest_eq(f(1.), FS(1.))\n\nIf the function returns a subclass of the annotated return type, that more specific type will be preserved since it’s already compatible with the annotation:\n\n@Transform\ndef f(x)-&gt;float: return FS(x)\n\n# FS output is kept because more specific than float\ntest_eq(f(1.), FS(1.))\n\nWhen return types are given, the conversion will even happen if the output type is not a subclass of the return type annotation:\n\n@Transform\ndef f(x)-&gt;str: return FS(x)\n\ntest_eq(f(1.), \"FS(1.0)\")\n\nAnd here we get an expected error because it’s not possible to match the explicit return type:\n\n@Transform\ndef f(x)-&gt;int: return str(x)\n\ntry: f(\"foo\")\nexcept Exception as e: print(f\"Caught Exception: {e=}\")\n\nCaught Exception: e=ValueError(\"invalid literal for int() with base 10: 'foo'\")\n\n\n\n\nType annotation with Decode\nJust like encodes, the decodes method will cast outputs to match the input type in the same way. In the below example, the output of decodes remains of type IntSubclass:\n\ndef enc(x): return FS(x+1)\ndef dec(x): return x-1\n\nf = Transform(enc,dec)\nt = f(1.0)  # t will be FS\ntest_eq_type(f.decode(t), FS(1.0))",
    "crumbs": [
      "Transform"
    ]
  },
  {
    "objectID": "transform.html#transforms-on-lists",
    "href": "transform.html#transforms-on-lists",
    "title": "Transform",
    "section": "Transforms on Lists",
    "text": "Transforms on Lists\nTransform operates on lists as a whole, not element-wise:\n\ndef enc(x): return dict(x)\ndef dec(x): return list(x.items())\n    \nf = Transform(enc,dec)\n_inp = [(1,2), (3,4)]\nt = f(_inp)\n\ntest_eq(t, dict(_inp))\ntest_eq(f.decodes(t), _inp)\n\nIf you want a transform to operate on a list elementwise, you must implement this appropriately in the encodes and decodes methods:\n\ndef enc(x): return [x_+1 for x_ in x]\ndef dec(x): return [x_-1 for x_ in x]\n\nf = Transform(enc,dec)\nt = f([1,2])\n\ntest_eq(t, [2,3])\ntest_eq(f.decode(t), [1,2])",
    "crumbs": [
      "Transform"
    ]
  },
  {
    "objectID": "transform.html#transforms-on-tuples",
    "href": "transform.html#transforms-on-tuples",
    "title": "Transform",
    "section": "Transforms on Tuples",
    "text": "Transforms on Tuples\nUnlike lists, Transform operates on tuples element-wise.\n\ndef neg_int(x): return -x\nf = Transform(neg_int)\n\ntest_eq(f((1,2,3)), (-1,-2,-3))\n\nTransforms will also apply TypedDispatch element-wise on tuples when an input type annotation is specified. In the below example, the values 1.0 and 3.0 are ignored because they are of type float, not int:\n\ndef neg_int(x:int): return -x\nf = Transform(neg_int)\n\ntest_eq(f((1.0, 2, 3.0)), (1.0, -2, 3.0))\n\nAnother example of how Transform can use TypedDispatch with tuples is shown below:\n\ndef enc1(x: int): return x+1\ndef enc2(x: str): return x+'hello'\ndef enc3(x): return str(x)+'!'\nf = Transform(enc=[enc1, enc2, enc3])\n\nIf the input is not an int or str, the third encodes method will apply:\n\ntest_eq(f([1]), '[1]!')\ntest_eq(f([1.0]), '[1.0]!')\n\nHowever, if the input is a tuple, then the appropriate method will apply according to the type of each element in the tuple:\n\ntest_eq(f(('1',)), ('1hello',))\ntest_eq(f((1,2)), (2,3))\ntest_eq(f(('a',1.0)), ('ahello','1.0!'))\n\nDispatching over tuples works recursively, by the way:\n\ndef enc1(x:int): return x+1\ndef enc2(x:str): return x+'_hello'\ndef dec1(x:int): return x-1\ndef dec2(x:str): return x.replace('_hello', '')\n\nf = Transform(enc=[enc1, enc2], dec=[dec1, dec2])\nstart = (1.,(2,'3'))\nt = f(start)\ntest_eq_type(t, (1.,(3,'3_hello')))\ntest_eq(f.decode(t), start)\n\nDispatching also works with typing module type classes, like numbers.integral:\n\n@Transform\ndef f(x:numbers.Integral): return x+1\n\nt = f((1,'1',1))\ntest_eq(t, (2, '1', 2))",
    "crumbs": [
      "Transform"
    ]
  },
  {
    "objectID": "transform.html#transform-on-subsets-with-split_idx",
    "href": "transform.html#transform-on-subsets-with-split_idx",
    "title": "Transform",
    "section": "Transform on subsets with split_idx",
    "text": "Transform on subsets with split_idx\n\ndef enc(x): return x+1\ndef dec(x): return x-1\nf = Transform(enc,dec)\nf.split_idx = 1\n\nThe transformations are applied when a matching split_idx parameter is passed:\n\ntest_eq(f(1, split_idx=1),2)\ntest_eq(f.decode(2, split_idx=1),1)\n\nOn the other hand, transformations are ignored when the split_idx parameter does not match:\n\ntest_eq(f(1, split_idx=0), 1)\ntest_eq(f.decode(2, split_idx=0), 2)",
    "crumbs": [
      "Transform"
    ]
  },
  {
    "objectID": "transform.html#extending-transform",
    "href": "transform.html#extending-transform",
    "title": "Transform",
    "section": "Extending Transform",
    "text": "Extending Transform\n\nLimitation of calling Transform directly\nHowever in this case it is not extendible, the previous implementation gets overwritten:\n\n@Transform\ndef g(x:int): return x*3\n\ntest_eq(g(2), 6)\ntest_eq(g('a'), 'a')  # &lt;- resorts to returning self\ntest_eq(len(g.encodes.methods), 1)\n\nFor extendible Transforms take a look at the “Extending the Transform class” section below\n\n\nSubclassing Transform\nWhen you subclass Transform you can define multiple encodes as methods directly.\n\nclass A(Transform):\n    def encodes(self, x:int): return x*2\n    def encodes(self, x:str): return f'hello {x}!'\ntest_eq(len(A.encodes.methods), 2)\n\n\na = A()\ntest_eq(a(2), 4)\ntest_eq(a('Alex'), \"hello Alex!\")\n\nContinued inheritance is supported\n\nclass B(A):\n    def encodes(self, x:int): return x*4\n    def encodes(self, x:float): return x/2\ntest_eq(len(B.encodes.methods), 3)\n\n\nb = B()\ntest_eq(b(2), 8)\ntest_eq(b('Alex'), 'hello Alex!')\ntest_eq(b(5.), 2.5)\n\nAs is multiple inheritance:\n\nclass A(Transform):\n    def encodes(self, x:int): return x*2\n    def encodes(self, x:str): return f'hello {x}!'\n\nclass B(Transform):\n    def encodes(self, x:int): return x*4\n    def encodes(self, x:float): return x/2\n\nclass C(B,A):  # C is preferred of B is preferred over A\n    def encodes(self, x:float): return x/4\n\ntest_eq(len(A.encodes.methods), 2)\ntest_eq(len(B.encodes.methods), 2)\ntest_eq(len(C.encodes.methods), 3)\n\n\nc = C()\ntest_eq(c('Alex'), 'hello Alex!')  # A's str method\ntest_eq(c(5), 20)  # B's int method\ntest_eq(c(10.), 2.5)  # C's float method\n\n\n\nExtensions with decorators\nAnother way to define a Transform is to extend the Transform class:\n\nclass A(Transform): pass\n\nAnd then use decorators:\n\n@A\ndef encodes(self, x:int): return x*2\n\n\n@A\ndef decodes(self,x:int): return x//2\n\n\ntest_eq(len(A.encodes.methods),1)\ntest_eq(len(A.decodes.methods),1)\n\n\na = A()\n\n\ntest_eq(a(5),10)\ntest_eq(a.decode(a(5)),5)\n\nNote that adding a method to a class (A) after instantiating the object (a):\n\n@A\ndef encodes(self, x:str): return f'hello {x}!'\n\nWill result in the method being accessible in both:\n\ntest_eq(len(A.encodes.methods),2)\ntest_eq(len(a.encodes.methods),2)",
    "crumbs": [
      "Transform"
    ]
  },
  {
    "objectID": "transform.html#predefined-transform-extensions",
    "href": "transform.html#predefined-transform-extensions",
    "title": "Transform",
    "section": "Predefined Transform extensions",
    "text": "Predefined Transform extensions\nBelow are some Transforms that may be useful as reusable components\n\nInplaceTransform\n\nsource\n\n\nInplaceTransform\n\n InplaceTransform (enc=None, dec=None, split_idx=None, order=None)\n\nA Transform that modifies in-place and just returns whatever it’s passed\n\nclass A(InplaceTransform): pass\n\n@A\ndef encodes(self, x:pd.Series): x.fillna(10, inplace=True)\n    \nf = A()\n\ntest_eq_type(f(pd.Series([1,2,None])),pd.Series([1,2,10],dtype=np.float64)) #fillna fills with floats.\n\n\n\nDisplayedTransform\n\nsource\n\n\nDisplayedTransform\n\n DisplayedTransform (enc=None, dec=None, split_idx=None, order=None)\n\nA transform with a __repr__ that shows its attrs\nTransforms normally are represented by just their class name and a number of encodes and decodes implementations:\n\nclass A(Transform): encodes,decodes = noop,noop\nf = A()\nf\n\nA(enc:2,dec:2)\n\n\nA DisplayedTransform will in addition show the contents of all attributes listed in the comma-delimited string self.store_attrs:\n\nclass A(DisplayedTransform):\n    encodes = noop\n    def __init__(self, a, b=2):\n        super().__init__()\n        store_attr()\n    \nA(a=1,b=2)\n\nA -- {'a': 1, 'b': 2}\n(enc:2,dec:0)\n\n\n\n\nItemTransform\n\nsource\n\n\nItemTransform\n\n ItemTransform (enc=None, dec=None, split_idx=None, order=None)\n\nA transform that always take tuples as items\nItemTransform is the class to use to opt out of the default behavior of Transform.\n\nclass AIT(ItemTransform): \n    def encodes(self, xy): x,y=xy; return (x+y,y)\n    def decodes(self, xy): x,y=xy; return (x-y,y)\n    \nf = AIT()\ntest_eq(f((1,2)), (3,2))\ntest_eq(f.decode((3,2)), (1,2))\n\nIf you pass a special tuple subclass, the usual retain type behavior of Transform will keep it:\n\nclass _T(tuple): pass\nx = _T((1,2))\ntest_eq_type(f(x), _T((3,2)))\n\n\n\nFunc\n\nsource\n\n\nget_func\n\n get_func (t, name, *args, **kwargs)\n\nGet the t.name (potentially partial-ized with args and kwargs) or noop if not defined\nThis works for any kind of t supporting getattr, so a class or a module.\n\ntest_eq(get_func(operator, 'neg', 2)(), -2)\ntest_eq(get_func(operator.neg, '__call__')(2), -2)\ntest_eq(get_func(list, 'foobar')([2]), [2])\na = [2,1]\nget_func(list, 'sort')(a)\ntest_eq(a, [1,2])\n\nTransforms are built with multiple-dispatch: a given function can have several methods depending on the type of the object received. This is done with the Plum module and type-annotation in Transform, but you can also use the following class.\n\nsource\n\n\nFunc\n\n Func (name, *args, **kwargs)\n\nBasic wrapper around a name with args and kwargs to call on a given type\nYou can call the Func object on any module name or type, even a list of types. It will return the corresponding function (with a default to noop if nothing is found) or list of functions.\n\ntest_eq(Func('sqrt')(math), math.sqrt)\n\n\n\n\nSig\n\n Sig (*args, **kwargs)\n\n\n\nSig\nSig is just sugar-syntax to create a Func object more easily with the syntax Sig.name(*args, **kwargs).\n\nf = Sig.sqrt()\ntest_eq(f(math), math.sqrt)",
    "crumbs": [
      "Transform"
    ]
  },
  {
    "objectID": "transform.html#methods",
    "href": "transform.html#methods",
    "title": "Transform",
    "section": "Methods",
    "text": "Methods\n\nsource\n\nPipeline.__call__\n\n Pipeline.__call__ (o)\n\nCall self as a function.\n\nsource\n\n\nPipeline.decode\n\n Pipeline.decode (o, full=True)\n\n\nsource\n\n\nPipeline.setup\n\n Pipeline.setup (items=None, train_setup=False)\n\nDuring the setup, the Pipeline starts with no transform and adds them one at a time, so that during its setup, each transform gets the items processed up to its point and not after.",
    "crumbs": [
      "Transform"
    ]
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Welcome to fasttransform",
    "section": "",
    "text": "Install latest from the GitHub repository:\n$ pip install git+https://github.com/AnswerDotAI/fasttransform.git\nor from pypi:\n$ pip install fasttransform",
    "crumbs": [
      "Welcome to fasttransform"
    ]
  },
  {
    "objectID": "index.html#installation",
    "href": "index.html#installation",
    "title": "Welcome to fasttransform",
    "section": "",
    "text": "Install latest from the GitHub repository:\n$ pip install git+https://github.com/AnswerDotAI/fasttransform.git\nor from pypi:\n$ pip install fasttransform",
    "crumbs": [
      "Welcome to fasttransform"
    ]
  },
  {
    "objectID": "index.html#quick-start",
    "href": "index.html#quick-start",
    "title": "Welcome to fasttransform",
    "section": "Quick start",
    "text": "Quick start\n\nTransform\nTransform is a class that lets you create reusable data transformations. You initialize a Transform by passing in or decorating a raw function. The Transform then provides an enhanced version of that function via Transform.encodes, which can be used in your data pipeline.\nIt provides various conveniences:\n\nReversibility. You can collect the raw function and its inverse into one transform object.\nCustomized initialization You can customize the exact behavior of a transform function on initialization.\nType-based mulitiple dispatch. Transforms can specialize their behavior based on the runtime types of their arguments.\nType conversion/preservation. Transforms help you maintain desired return types.\n\nThe simplest way to create a Transform is by decorating a function:\n\nfrom fasttransform import Transform, Pipeline\n\n\n@Transform\ndef add_one(x): \n    return x + 1\n\n# Usage\nadd_one(2)\n\n3\n\n\n\n\nReversibility\nTo make a transform reversible, you provide the raw function and its inverse. This is useful in data pipelines where, for instance, you might want to normalize and then de-normalize numerical values, or encode to category indexes and then decode back to categories.\n\ndef enc(x): return x*2\ndef dec(x): return x//2\n\nt = Transform(enc,dec)\n\nt(2), t.decode(2), t.decode(t(2))\n\n(4, 1, 2)\n\n\n\n\nCustomized initialization\nYou can customize an individual Transform instance at initialization time, so that it can depend on aggregate properties of the data set.\nHere we define a z-score normalization Transform by defining encodes and decodes methods directly:\n\nimport statistics\n\nclass NormalizeMean(Transform):\n    def setups(self, items): \n        self.mean = statistics.mean(items)\n        self.std  = statistics.stdev(items)\n    \n    def encodes(self, x): \n        return (x - self.mean) / self.std\n    \n    def decodes(self, x): \n        return x * self.std + self.mean\n\nnormalize = NormalizeMean()\nnormalize.setup([1, 2, 3, 4, 5])\nnormalize.mean\n\n3\n\n\n\n\nType-based multiple dispatch\nInstead of providing one raw functions, you can provide multiple raw functions which differ in their parameter types. Tranform will use type-based dispatch to automatically execute the correct function.\nThis is handy when your inputs come in different types (eg., different image formats, different numerical types).\n\ndef inc1(x:int): return x+1\ndef inc2(x:str): return x+\"a\"\n\nt = Transform(enc=(inc1,inc2))\n\nt(5), t('b')\n\n(6, 'ba')\n\n\nIf an input type does not match any of the type annotations then the original input is returned.\n\nadd_one(2.0)\n\n3.0\n\n\n\nnormalize(3.0)\n\n0.0\n\n\n\n\nType conversion/preservation\nYou initialize a Transform by passing in or decorating a raw function.\nA Transform encodes or decodes will note the return type of its raw function, which may be defined explicitly or implicitly, and enhance type-handling behavior in three ways:\n\nGuaranteed return type. It will always return the return type of the raw function, promoting values if necessary.\nType Preservation. It will return the runtime type of its argument, whenever that is a subtype of the return type.\nOpt-out conversion. If you explicitly mark the raw function’s return type as None, then it will not perform any type conversion or preservation.\n\nExamples help make this clear:\n\nGuaranteed return type\nSay you define FS, a subclass of float. The usual Python type promotion behavior means that an FS times a float is still a float:\n\nclass FS(float):\n  def __repr__(self): return f'FS({float(self)})'\n \nf1 = float(1)\nFS2 = FS(2)\n\nval = f1 * FS2\ntype(val) # =&gt; float\n\nfloat\n\n\nWith Transform, you can define a new multiplication operation which will be guaranteed to return a FS, because Transform reads the required raw function’s annotated return type:\n\ndef double_FS(x)-&gt;FS: return FS(2)*x\nt = Transform(double_FS)\nval = t(1) \nassert isinstance(val,FS)\nval\n\nFS(2.0)\n\n\n\n\nType preservation\nLet us say that we define a transform without any return type annotation, so that the raw function is defined only by the behavior of multiplying its argument by the float 2.0.\nMultiplying the subtype FS with the float value 2 would normally return a float. However, Transform’s encodes will preserve the runtime type of its argument, so that it returns FS:\n\ndef double(x): return x*2.0  # no type annotation\nt = Transform(double)\nfs1 = FS(1)\nval = t(fs1)\nassert isinstance(val,FS)\nval # =&gt; FS(2), an FS value of 2\n\nFS(2.0)\n\n\n\n\nOpt-out conversion\nSometimes you don’t want Transform to do any type-based logic. You can opt-out of this system by declaring that your raw function’s return type is None:\n\ndef double_none(x) -&gt; None: return x*2.0  # \"None\" returnt type means \"no conversion\"\nt = Transform(double_none)\nfs1 = FS(1)\nval = t(fs1)\nassert isinstance(val,float)\nval # =&gt; 2.0, a float of 2, because of fallback to standard Python type logic\n\n2.0\n\n\n\n\n\nPipelines\nTransforms can be combined into larger Pipelines:\n\ndef double(x): return x*2.0 \ndef halve(x): return x/2.0\ndt = Transform(double,halve)\n\nclass NormalizeMean(Transform):\n    def setups(self, items): \n        self.mean = statistics.mean(items)\n        self.std  = statistics.stdev(items)\n    \n    def encodes(self, x):\n        return (x - self.mean) / self.std\n    \n    def decodes(self, x):\n        return x * self.std + self.mean\n\n\np = Pipeline((dt, normalize))\n\nv = p(5)\nv\n\n4.427188724235731\n\n\n\np.decode(v)\n\n5.0\n\n\n\n\nDocumentation\nThis was just a quickstart. Learn more by reading the documentation.",
    "crumbs": [
      "Welcome to fasttransform"
    ]
  }
]