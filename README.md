# Welcome to fasttransform


<!-- WARNING: THIS FILE WAS AUTOGENERATED! DO NOT EDIT! -->

## Installation

Install latest from the GitHub
[repository](https://github.com/AnswerDotAI/fasttransform):

``` sh
$ pip install git+https://github.com/AnswerDotAI/fasttransform.git
```

or from [pypi](https://pypi.org/project/fasttransform/):

``` sh
$ pip install fasttransform
```

## Quick start

### Transform

Transform is a class that lets you create reusable data transformations.
It behaves like a function, you can call it to `encode` your data. In
addition it has an optional `decode` method that will reverse the
function. And an optional `setup` method that can initialize some inner
state.

The simplest way to create a Transform is by decorating a function:

``` python
from fasttransform import Transform, Pipeline
```

``` python
@Transform
def add_one(x: int): 
    return x + 1

# Usage
add_one(2)
```

    3

Transforms are **flexible**. You can specify multiple transforms with
different type annotations and it will automatically pick up the correct
one.

``` python
def inc1(x:int): return x+1
def inc2(x:str): return x+"a"

t = Transform(enc=(inc1,inc2))

t(5), t('b')
```

    (6, 'ba')

If an input type does not match any of the type annotations then the
original input is returned.

``` python
add_one(2.0)
```

    2.0

Transforms are **reversible**, if you provide a `decode` function.

``` python
def enc(x): return x*2
def dec(x): return x//2

t = Transform(enc,dec)

t(2), t.decode(2), t.decode(t(2))
```

    (4, 1, 2)

Transforms can be **stateful**, you can initialize them with the `setup`
method. This may be useful when you want to set scaling parameters based
on your training split in your machine learning pipeline.

``` python
class NormalizeMean(Transform):
    def setups(self, items): 
        self.mean = sum(items) / len(items)
    
    def encodes(self, x): 
        return x - self.mean
    
    def decodes(self, x): 
        return x + self.mean

normalize = NormalizeMean()
normalize.setup([1, 2, 3, 4, 5])
normalize.mean
```

    3.0

``` python
normalize(3.0)
```

    0.0

Transforms are **extendedible**, this may be useful when you want to
create one Transform that can handle different data types.

``` python
@NormalizeMean
def encodes(self, x:float): return x + self.mean + 5

@NormalizeMean
def decodes(self, x:float): return x + self.mean + 5

normalize(2.0)
```

    10.0

Transforms try to be **type preserving** in the following order:

1.  your function’s return type annotation
2.  your function’s actual input type, if it was a subtype of the return
    value
3.  if None is the return type annotation then no conversion will be
    done

Let’s illustrate this with an example of a custom `float` subtype:

``` python
class FS(float):
    def __repr__(self): return f'FS({float(self)})'
```

By default multiplying such a subtype with a regular `float` returns a
`float`.

``` python
FS(5.0) * 5.0
```

    25.0

However, in Transform you can change this behavior with type
annotations.

Illustration of case 1:

``` python
def enc(x)->FS: return x*2
t = Transform(enc)
t(1)
```

    FS(2.0)

Illustration of case 2:

``` python
def enc(x): return x*2
t = Transform(enc)
t(FS(1))
```

    FS(2.0)

Note that in the case below, where the input is a `float` and the return
type is `FS` there’s not conversion. The reason is: we can’t make sure
some special information about `FS` is lost when converting to its
parent class `float`.

``` python
def enc(x): return FS(x*2)
t = Transform(enc)
t(1.0)
```

    FS(2.0)

Illustration of case 3:

``` python
def enc(x)->None: return x*2
t = Transform(enc)
t(FS(1))
```

    2.0

In the last case we see a `float` because a mutiplication of `FS` with a
`float` returns a `float` and no additional type conversion is done.

### Pipelines

Transforms can be combined into larger **Pipelines**:

``` python
p = Pipeline((t, normalize))

p(5)  # 5 * 2 - 3
```

    7.0

``` python
p.decode(7) # (7 + 3) / 2
```

    10.0

If you’re wondering the types are changing from `int` to `float` in this
case:

`self.mean` in the `NormalizeMean` transform is a `float`. So the
automatic type conversion does not trigger here, as `float` is not a
subtype of `int`. And that’s probably a good thing, because otherwise we
might lose some information here whenever `self.mean` has some decimal
value.

### Documentation

This was just a quickstart. Learn more by reading the
[documentation](https://github.io/AnswerDotAI/fasttransform).
