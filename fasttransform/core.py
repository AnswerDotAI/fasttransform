"""Definition of `Transform` and `Pipeline`"""

# AUTOGENERATED! DO NOT EDIT! File to edit: ../nbs/00_core.ipynb.

# %% auto 0
__all__ = ['retain_type', 'Transform', 'compose_tfms', 'mk_transform', 'gather_attrs', 'Pipeline']

# %% ../nbs/00_core.ipynb 1
from typing import Any

from fastcore.imports import *
from fastcore.foundation import *
from fastcore.utils import *
from fastcore.dispatch import retain_meta, cast  # move to fasttransform

from plum.function import Function
from plum import NotFoundLookupError
from fastcore.dispatch import retain_type

# %% ../nbs/00_core.ipynb 6
def _is_tuple(o): return isinstance(o, tuple) and not hasattr(o, '_fields')

# %% ../nbs/00_core.ipynb 7
def retain_type(new, old, ret_type,as_copy=False):
    if new is None: return new
    if ret_type is NoneType: return new
    if ret_type is Any:
        if not isinstance(old, type(new)): return new
        ret_type = old if isinstance(old,type) else type(old)
    if ret_type is NoneType or isinstance(new,ret_type): return new
    # fastcore.retain_meta and cast are used because
    # the retain_meta logic is embedded in fastai (and torch itself?)
    # see 00_torch_core set_meta functions.
    return retain_meta(old, cast(new, ret_type), as_copy=as_copy)
    

# %% ../nbs/00_core.ipynb 14
_tfm_methods = 'encodes','decodes','setups'

def _is_tfm_method(n, f): return n in _tfm_methods and callable(f)

class _TfmDict(dict):
    def __setitem__(self, k, v):
        if not _is_tfm_method(k, v): return super().__setitem__(k,v)
        if k not in self: super().__setitem__(k,Function(v).dispatch(v))
        self[k].dispatch(v)
     

# %% ../nbs/00_core.ipynb 15
class _TfmMeta(type):
    @classmethod
    def __prepare__(cls, name, bases): 
        return _TfmDict()

# %% ../nbs/00_core.ipynb 18
def _has_self_arg(f) -> bool:
    "Check if function `f` has 'self' as first parameter"
    try: return f.__code__.co_varnames[0] == 'self'
    # Attribute error if not callable
    # IndexError if no (kw)args
    except (AttributeError, IndexError): return False

# %% ../nbs/00_core.ipynb 19
def _subclass_decorator(cls, f):
    nm = f.__name__
    # needed for plum to register dispatch correctly
    # f.__qualname__ = f"{cls.__name__}.{nm}"
    if not hasattr(cls, nm): setattr(cls, nm, Function(f).dispatch(f))
    else: getattr(cls,nm).dispatch(f)
    return cls

# %% ../nbs/00_core.ipynb 20
class Transform(metaclass=_TfmMeta):
    "Delegates (`__call__`,`decode`,`setup`) to (<code>encodes</code>,<code>decodes</code>,<code>setups</code>) if `split_idx` matches"
    
    def __init_subclass__(cls):
        # convert _tfm_methods that aren't plum.Functions yet
        for nm in _tfm_methods:
            if hasattr(cls, nm) and not isinstance(getattr(cls, nm), Function):
                f = getattr(cls, nm)
                setattr(cls, nm, Function(f).dispatch(f))

        # Add binding logic to subclass __init__
        # TODO: double check needed and if args kwargs in there?
        def __init__(self):
            for nm in _tfm_methods:
                if hasattr(self.__class__, nm):
                    setattr(self, nm, MethodType(getattr(self.__class__, nm), self))
    
        cls.__init__ = __init__

    def __new__(cls, enc=None, dec=None):
        # subclass of Transform decorator usage
        if (
            issubclass(cls,Transform) and   
            _has_self_arg(enc) and
            enc.__name__ in _tfm_methods and
            dec is None
        ): return _subclass_decorator(cls, enc)
        # default usecase
        return super().__new__(cls)

    def __init__(self,enc=None,dec=None):
        enc = L(enc)
        if enc: self.encodes = Function(enc[0])
        for e in enc: self.encodes.dispatch(e)

        dec = L(dec)
        if dec: self.decodes = Function(dec[0])
        for d in dec: self.decodes.dispatch(d)

    def __call__(self,*args,**kwargs):
        return self._do_call('encodes',*args,**kwargs)
    
    def decode(self, *args, **kwargs):
        return self._do_call('decodes',*args, **kwargs)
    
    def setup(self, *args, **kwargs):
        raise NotImplementedError()
        
    def _do_call(self, nm, *args, **kwargs): 
        x = args[0]
        if not hasattr(self, nm): return x
        if _is_tuple(x):
            res = tuple(self._do_call(nm, x_, *args[1:], **kwargs) for x_ in x)
            return retain_type(res, x, Any)
        
        f_args = args if type(self) is Transform else (self,)+args
        try:
            method, ret_type = getattr(self,nm)._resolve_method_with_cache(f_args)
        except NotFoundLookupError: 
            return x
        res = method(*f_args,**kwargs)
        return retain_type(res, x, ret_type)
    
add_docs(Transform, decode="Delegate to decodes to undo transform", setup="Delegate to setups to set up transform")

# %% ../nbs/00_core.ipynb 110
def compose_tfms(x, tfms, is_enc=True, reverse=False, **kwargs):
    "Apply all `func_nm` attribute of `tfms` on `x`, maybe in `reverse` order"
    if reverse: tfms = reversed(tfms)
    for f in tfms:
        if not is_enc: f = f.decode
        x = f(x, **kwargs)
    return x
     

# %% ../nbs/00_core.ipynb 115
def mk_transform(f):
    "Convert function `f` to `Transform` if it isn't already one"
    f = instantiate(f)
    return f if isinstance(f,(Transform,Pipeline)) else Transform(f)

# %% ../nbs/00_core.ipynb 116
def gather_attrs(o, k, nm):
    "Used in __getattr__ to collect all attrs `k` from `self.{nm}`"
    if k.startswith('_') or k==nm: raise AttributeError(k)
    att = getattr(o,nm)
    res = [t for t in att.attrgot(k) if t is not None]
    if not res: raise AttributeError(k)
    return res[0] if len(res)==1 else L(res)

# %% ../nbs/00_core.ipynb 117
class Pipeline:
    "A pipeline of composed (for encode/decode) transforms, setup with types"
    def __init__(self, funcs=None, split_idx=None):
        self.split_idx,self.default = split_idx,None
        if funcs is None: funcs = []
        if isinstance(funcs, Pipeline): self.fs = funcs.fs
        else:
            if isinstance(funcs, Transform): funcs = [funcs]
            self.fs = L(ifnone(funcs,[noop])).map(mk_transform).sorted(key='order')
        for f in self.fs:
            name = camel2snake(type(f).__name__)
            a = getattr(self,name,None)
            if a is not None: f = L(a)+f
            setattr(self, name, f)

    def setup(self, items=None, train_setup=False):
        tfms = self.fs[:]
        self.fs.clear()
        for t in tfms: self.add(t,items, train_setup)

    def add(self,ts, items=None, train_setup=False):
        if not is_listy(ts): ts=[ts]
        for t in ts: t.setup(items, train_setup)
        self.fs+=ts
        self.fs = self.fs.sorted(key='order')

    def __call__(self, o): return compose_tfms(o, tfms=self.fs, split_idx=self.split_idx)
    def __repr__(self): return f"Pipeline: {' -> '.join([f.name for f in self.fs if f.name != 'noop'])}"
    def __getitem__(self,i): return self.fs[i]
    def __setstate__(self,data): self.__dict__.update(data)
    def __getattr__(self,k): return gather_attrs(self, k, 'fs')
    def __dir__(self): return super().__dir__() + gather_attr_names(self, 'fs')

    def decode  (self, o, full=True):
        if full: return compose_tfms(o, tfms=self.fs, is_enc=False, reverse=True, split_idx=self.split_idx)
        #Not full means we decode up to the point the item knows how to show itself.
        for f in reversed(self.fs):
            if self._is_showable(o): return o
            o = f.decode(o, split_idx=self.split_idx)
        return o

    def show(self, o, ctx=None, **kwargs):
        o = self.decode(o, full=False)
        o1 = (o,) if not _is_tuple(o) else o
        if hasattr(o, 'show'): ctx = o.show(ctx=ctx, **kwargs)
        else:
            for o_ in o1:
                if hasattr(o_, 'show'): ctx = o_.show(ctx=ctx, **kwargs)
        return ctx

    def _is_showable(self, o):
        if hasattr(o, 'show'): return True
        if _is_tuple(o): return all(hasattr(o_, 'show') for o_ in o)
        return False
