"""Definition of `Transform` and `Pipeline`"""

# AUTOGENERATED! DO NOT EDIT! File to edit: ../nbs/00_core.ipynb.

# %% auto 0
__all__ = ['retain_type', 'Transform']

# %% ../nbs/00_core.ipynb 1
from typing import Any

from fastcore.imports import *
from fastcore.foundation import *
from fastcore.utils import *
from fastcore.dispatch import retain_meta, cast  # move to fasttransform

from plum.function import Function
from plum import NotFoundLookupError
from fastcore.dispatch import retain_type

# %% ../nbs/00_core.ipynb 6
def retain_type(new, old, ret_type,as_copy=False):
    if new is None: return new
    if ret_type is NoneType: return new
    if ret_type is Any:
        if not isinstance(old, type(new)): return new
        ret_type = old if isinstance(old,type) else type(old)
    if ret_type is NoneType or isinstance(new,ret_type): return new
    # fastcore.retain_meta and cast are used because
    # the retain_meta logic is embedded in fastai (and torch itself?)
    # see 00_torch_core set_meta functions.
    return retain_meta(old, cast(new, ret_type), as_copy=as_copy)
    

# %% ../nbs/00_core.ipynb 13
_tfm_methods = 'encodes','decodes','setups'

def _is_tfm_method(n, f): return n in _tfm_methods and callable(f)

class _TfmDict(dict):
    def __setitem__(self, k, v):
        if not _is_tfm_method(k, v): return super().__setitem__(k,v)
        if k not in self: super().__setitem__(k,Function(v).dispatch(v))
        self[k].dispatch(v)
     

# %% ../nbs/00_core.ipynb 14
class _TfmMeta(type):
    @classmethod
    def __prepare__(cls, name, bases): 
        return _TfmDict()

# %% ../nbs/00_core.ipynb 17
def _has_self_arg(f) -> bool:
    "Check if function `f` has 'self' as first parameter"
    try: return f.__code__.co_varnames[0] == 'self'
    # Attribute error if not callable
    # IndexError if no (kw)args
    except (AttributeError, IndexError): return False

# %% ../nbs/00_core.ipynb 18
def _subclass_decorator(cls, f):
    nm = f.__name__
    # needed for plum to register dispatch correctly
    # f.__qualname__ = f"{cls.__name__}.{nm}"
    if not hasattr(cls, nm): setattr(cls, nm, Function(f).dispatch(f))
    else: getattr(cls,nm).dispatch(f)
    return cls

# %% ../nbs/00_core.ipynb 19
class Transform(metaclass=_TfmMeta):
    "Delegates (`__call__`,`decode`,`setup`) to (<code>encodes</code>,<code>decodes</code>,<code>setups</code>) if `split_idx` matches"
    
    def __init_subclass__(cls):
        # convert _tfm_methods that aren't plum.Functions yet
        for nm in _tfm_methods:
            if hasattr(cls, nm) and not isinstance(getattr(cls, nm), Function):
                f = getattr(cls, nm)
                setattr(cls, nm, Function(f).dispatch(f))

        # Add binding logic to subclass __init__
        def __init__(self):
            for nm in _tfm_methods:
                if hasattr(self.__class__, nm):
                    setattr(self, nm, MethodType(getattr(self.__class__, nm), self))
    
        cls.__init__ = __init__

    def __new__(cls, enc=None, dec=None):
        # subclass of Transform decorator usage
        if (
            issubclass(cls,Transform) and   
            _has_self_arg(enc) and
            enc.__name__ in _tfm_methods and
            dec is None
        ): return _subclass_decorator(cls, enc)
        # default usecase
        return super().__new__(cls)

    def __init__(self,enc=None,dec=None):
        enc = L(enc)
        if enc: self.encodes = Function(enc[0])
        for e in enc: self.encodes.dispatch(e)

        dec = L(dec)
        if dec: self.decodes = Function(dec[0])
        for d in dec: self.decodes.dispatch(d)

    def __call__(self,*args,**kwargs):
        return self._do_call('encodes',*args,**kwargs)
    
    def decode(self, *args, **kwargs):
        return self._do_call('decodes',*args, **kwargs)
    
    def setup(self, *args, **kwargs):
        raise NotImplementedError()
        
    def _do_call(self, nm, *args, **kwargs): 
        if not hasattr(self, nm): return args[0]
        f_args = args if type(self) is Transform else (self,)+args
        try:
            method, ret_type = getattr(self,nm)._resolve_method_with_cache(f_args)
        except NotFoundLookupError: 
            return args[0]
        res = method(*f_args,**kwargs)
        return retain_type(res, args[0], ret_type)
    
add_docs(Transform, decode="Delegate to decodes to undo transform", setup="Delegate to setups to set up transform")
